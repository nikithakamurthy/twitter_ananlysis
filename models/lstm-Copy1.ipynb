{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import nltk.data\n",
    "import csv\n",
    "from nltk.stem.porter import *\n",
    "pd.options.mode.chained_assignment = None\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numpy import array as arr\n",
    "from numpy import argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data from dataset\n",
    "#data = pd.read_csv(\"mbti_1.csv\") \n",
    "#shortdata=data.iloc[:,-1]\n",
    "arr=[]\n",
    "file = open(\"downloaded1.csv\",'rt')\n",
    "samples=csv.reader(file)\n",
    "c=0\n",
    "for i in samples:\n",
    "    c+=1\n",
    "    \n",
    "    if c==2:\n",
    "        x=i[1]\n",
    "        break\n",
    "\n",
    "for i in samples:\n",
    "    if i[1]!=x:\n",
    "        arr.append(i)\n",
    "\n",
    "data=arr\n",
    "df=pd.DataFrame(data=arr,columns=(\"types\",\"posts\"))\n",
    "#print(len(df.columns))\n",
    "#print(df)\n",
    "#shortdata=shortdata.head()\n",
    "#shortdata1=data.iloc[0:5,0]\n",
    "#print('-----Data-------')\n",
    "#print(shortdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'neutral', 'positive']\n"
     ]
    }
   ],
   "source": [
    "def labelencode(df):\n",
    "    data=df['types']\n",
    "    values=np.array(data)\n",
    "    label=LabelEncoder()\n",
    "    intencode=label.fit_transform(values)\n",
    "    df['typeint']=intencode\n",
    "    print(list(label.inverse_transform([0,1,2])))\n",
    "    #df['typeint'].plot(kind='hist')\n",
    "    #k=np.arange(0,16)\n",
    "    #x=label.inverse_transform(k)   #can access encoded actual value using x\n",
    "    #print(values)\n",
    "    return df\n",
    "\n",
    "df=labelencode(df)\n",
    "#print(df)\n",
    "shortdata=df.iloc[:,1]\n",
    "#print(shortdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Removing stopwords------\n",
      "-------Stemming--------\n"
     ]
    }
   ],
   "source": [
    "#removing stopwords \n",
    "from nltk.corpus import stopwords\n",
    "stop=stopwords.words(\"english\")\n",
    "print('------Removing stopwords------')\n",
    "shortdata=shortdata.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "#shortdata=shortdata.apply(lambda x: ' '.join([word for word in x.split() if word!='i' or word!='I']))\n",
    "#print(shortdata)\n",
    "#stemming of words\n",
    "ps = PorterStemmer()\n",
    "print('-------Stemming--------')\n",
    "shortdata = shortdata.apply(lambda x: ' '.join([ps.stem(word) for word in x.split() ]))\n",
    "#print(shortdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Lemmatization--------\n",
      "--------Removing punctuations--------\n"
     ]
    }
   ],
   "source": [
    "#removing non-alphabets\n",
    "shortdata=shortdata.apply(lambda x: ' '.join([word for word in x.split() if word.isalpha()]))\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lmtzr = WordNetLemmatizer()\n",
    "#print(shortdata)\n",
    "print('-------Lemmatization--------')\n",
    "shortdata = shortdata.apply(lambda x: ' '.join([lmtzr.lemmatize(word,'v') for word in x.split() ]))\n",
    "#print(shortdata)\n",
    "\n",
    "print('--------Removing punctuations--------')\n",
    "def clear_punctuation(s):\n",
    "\timport string\n",
    "\t#print(\"\\n\")\n",
    "\tclear_string = \"\"\n",
    "\tfor symbol in s:\n",
    "\t\tif symbol not in string.punctuation:\n",
    "\t\t\tclear_string += symbol\n",
    "\treturn clear_string\n",
    "\n",
    "shortdata = shortdata.apply(lambda x: ''.join(clear_punctuation(x))  )\n",
    "#print(shortdata)\n",
    "#for line in shortdata:\n",
    "#\tprint(line)\n",
    "#\tprint('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_all_entities(text):\n",
    "\timport string\n",
    "\tentity_prefixes = ['@']\n",
    "\tfor separator in  string.punctuation:\n",
    "\t\tif separator not in entity_prefixes :\n",
    "\t\t\ttext = text.replace(separator,' ')\n",
    "\twords = []\n",
    "\tfor word in text.split():\n",
    "\t\tword = word.strip()\n",
    "\t\tif word:\n",
    "\t\t\tif word[0] not in entity_prefixes:\n",
    "\t\t\t\twords.append(word)\n",
    "\treturn ' '.join(words)\n",
    "\n",
    "shortdata = shortdata.apply(lambda x: ''.join(strip_all_entities(x))  ) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----PREPROCESSED_DATA------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'for column in dataset.columns:\\n    if dataset[column].dtype == type(object):\\n        le = LabelEncoder()\\n        dataset[column] = le.fit_transform(dataset[column])'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "arr=[]\n",
    "print(\"-----PREPROCESSED_DATA------\")\n",
    "count=0\n",
    "for line in shortdata:\n",
    "    df.iloc[i,1]=line\n",
    "    i=i+1\n",
    "#print(df)\n",
    "\n",
    "\n",
    "\n",
    "'''for column in dataset.columns:\n",
    "    if dataset[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        dataset[column] = le.fit_transform(dataset[column])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6936\n",
      "6936\n"
     ]
    }
   ],
   "source": [
    "proc_data=np.array(df['posts'])\n",
    "label=np.array(df['typeint'])\n",
    "print(len(proc_data))\n",
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(proc_data, label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kurt may drug possibl root beer find after murder'\n",
      " 'wabasha get brouhaha tuesday hear cup sand load the sand question us'\n",
      " 'idk whip full beyonc new CD night almost kill IM self preserv bro' ...\n",
      " 'australian littl thing play radio monday afternoon hit'\n",
      " 'maino great album beat nigga type person need hip hop'\n",
      " 'My roommat go eastern']\n"
     ]
    }
   ],
   "source": [
    "print(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import keras\n",
    "import keras.preprocessing.text as kpt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# only work with the 3000 most popular words found in our dataset\n",
    "max_words = 5000\n",
    "\n",
    "# create a new Tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "# feed our tweets to the Tokenizer\n",
    "tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "# Tokenizers come with a convenient list of words and IDs\n",
    "dictionary = tokenizer.word_index\n",
    "# Let's save this out so we can use it later\n",
    "with open('dictionary.json', 'w') as dictionary_file:\n",
    "    json.dump(dictionary, dictionary_file)\n",
    "\n",
    "\n",
    "def convert_text_to_index_array(text):\n",
    "    # one really important thing that `text_to_word_sequence` does\n",
    "    # is make all texts the same length -- in this case, the length\n",
    "    # of the longest text in the set.\n",
    "    return [dictionary[word] for word in kpt.text_to_word_sequence(text)]\n",
    "\n",
    "allWordIndices = []\n",
    "# for each tweet, change each token to its ID in the Tokenizer's word_index\n",
    "for text in train_x:\n",
    "    wordIndices = convert_text_to_index_array(text)\n",
    "    allWordIndices.append(wordIndices)\n",
    "\n",
    "# now we have a list of all tweets converted to index arrays.\n",
    "# cast as an array for future usage.\n",
    "allWordIndices = np.asarray(allWordIndices)\n",
    "\n",
    "# create one-hot matrices out of the indexed tweets\n",
    "train_x = tokenizer.sequences_to_matrix(allWordIndices, mode='binary')\n",
    "# treat the labels as categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = keras.utils.to_categorical(train_y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_shape=(max_words,), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "sgd=keras.optimizers.SGD(lr=0.5, momentum=0.0, decay=0.0, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "  optimizer=sgd,\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4993 samples, validate on 555 samples\n",
      "Epoch 1/5\n",
      "4993/4993 [==============================] - 3s 590us/step - loss: 0.9267 - acc: 0.5658 - val_loss: 1.3787 - val_acc: 0.1802\n",
      "Epoch 2/5\n",
      "4993/4993 [==============================] - 3s 528us/step - loss: 0.7766 - acc: 0.6593 - val_loss: 1.3640 - val_acc: 0.5171\n",
      "Epoch 3/5\n",
      "4993/4993 [==============================] - 3s 534us/step - loss: 0.6376 - acc: 0.7304 - val_loss: 2.8361 - val_acc: 0.1928\n",
      "Epoch 4/5\n",
      "4993/4993 [==============================] - 3s 527us/step - loss: 0.5647 - acc: 0.7713 - val_loss: 0.8475 - val_acc: 0.6468\n",
      "Epoch 5/5\n",
      "4993/4993 [==============================] - 3s 532us/step - loss: 0.4144 - acc: 0.8436 - val_loss: 0.9475 - val_acc: 0.6018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f79907750f0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y,\n",
    "  batch_size=32,\n",
    "  epochs=5,\n",
    "  verbose=1,\n",
    "  validation_split=0.1,\n",
    "  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open('model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.preprocessing.text as kpt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# we're still going to use a Tokenizer here, but we don't need to fit it\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "# for human-friendly printing\n",
    "labels = ['negative','neutral','positive']\n",
    "\n",
    "# read in our saved dictionary\n",
    "with open('dictionary.json', 'r') as dictionary_file:\n",
    "    dictionary = json.load(dictionary_file)\n",
    "\n",
    "# this utility makes sure that all the words in your input\n",
    "# are registered in the dictionary\n",
    "# before trying to turn them into a matrix.\n",
    "def convert_text_to_index_array(text):\n",
    "    words = kpt.text_to_word_sequence(text)\n",
    "    wordIndices = []\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            wordIndices.append(dictionary[word])\n",
    "        else:\n",
    "            print(\"'%s' not in training corpus; ignoring.\" %(word))\n",
    "    return wordIndices\n",
    "\n",
    "# read in your saved model structure\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "# and create a model from that\n",
    "model = model_from_json(loaded_model_json)\n",
    "# and weight your nodes with your saved values\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "# okay here's the interactive part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'are' not in training corpus; ignoring.\n",
      "neutral sentiment; 50.361705% confidence\n"
     ]
    }
   ],
   "source": [
    "eval=\"hello how are you?\"\n",
    "testArr = convert_text_to_index_array(eval)\n",
    "inp = tokenizer.sequences_to_matrix([testArr], mode='binary')\n",
    "# predict which bucket your input belongs in\n",
    "pred = model.predict(inp)\n",
    "# and print it for the humons\n",
    "print(\"%s sentiment; %f%% confidence\" % (labels[np.argmax(pred)], pred[0][np.argmax(pred)] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['offici tom boonen ride olymp saturday' 'bro get fafsa do last'\n",
      " 'At rick cafe watch dese guy jump cliff drink rum runner sun' ...\n",
      " 'Oh iight I dig go act tomorrow night tho young'\n",
      " 'intermiss FC take big step toward titl hard fight win fellow tabl topper the real ajax monday'\n",
      " 'jam blue tomgrant band thrill delight patron jammer good excus get NE']\n"
     ]
    }
   ],
   "source": [
    "print(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40131104 0.39161563 0.20707333]\n",
      "0.40131104\n",
      "negative\n",
      "[0.40316835 0.37755653 0.21927513]\n",
      "0.40316835\n",
      "negative\n",
      "'dese' not in training corpus; ignoring.\n",
      "[0.26061517 0.72447366 0.01491114]\n",
      "0.72447366\n",
      "neutral\n",
      "[0.74435616 0.23219463 0.02344927]\n",
      "0.74435616\n",
      "negative\n",
      "'cmag' not in training corpus; ignoring.\n",
      "'baag' not in training corpus; ignoring.\n",
      "'cmag' not in training corpus; ignoring.\n",
      "[0.09227023 0.06978171 0.8379481 ]\n",
      "0.8379481\n",
      "positive\n",
      "[4.7331353e-04 7.1370778e-05 9.9945527e-01]\n",
      "0.9994553\n",
      "positive\n",
      "[0.12335925 0.5432623  0.33337843]\n",
      "0.5432623\n",
      "neutral\n",
      "[0.51997316 0.37084663 0.1091802 ]\n",
      "0.51997316\n",
      "negative\n",
      "[0.00870403 0.06287035 0.92842567]\n",
      "0.92842567\n",
      "positive\n",
      "'statement' not in training corpus; ignoring.\n",
      "[0.11339714 0.8104727  0.07613022]\n",
      "0.8104727\n",
      "neutral\n",
      "'oooh' not in training corpus; ignoring.\n",
      "'ti' not in training corpus; ignoring.\n",
      "[0.10930403 0.06503188 0.82566404]\n",
      "0.82566404\n",
      "positive\n",
      "[0.08341546 0.22997104 0.68661344]\n",
      "0.68661344\n",
      "positive\n",
      "'lipton' not in training corpus; ignoring.\n",
      "[0.6915595  0.27952382 0.02891681]\n",
      "0.6915595\n",
      "negative\n",
      "'bmp' not in training corpus; ignoring.\n",
      "'hh' not in training corpus; ignoring.\n",
      "[0.03919719 0.8147129  0.14608991]\n",
      "0.8147129\n",
      "neutral\n",
      "'tia' not in training corpus; ignoring.\n",
      "'parole' not in training corpus; ignoring.\n",
      "[2.286728e-04 4.507169e-03 9.952642e-01]\n",
      "0.9952642\n",
      "positive\n",
      "'aye' not in training corpus; ignoring.\n",
      "'lollll' not in training corpus; ignoring.\n",
      "[0.3154947  0.63877016 0.04573514]\n",
      "0.63877016\n",
      "neutral\n",
      "[0.12930596 0.68589115 0.18480283]\n",
      "0.68589115\n",
      "neutral\n",
      "[0.8924291  0.07833968 0.02923124]\n",
      "0.8924291\n",
      "negative\n",
      "'ae' not in training corpus; ignoring.\n",
      "[0.02405963 0.28321725 0.6927231 ]\n",
      "0.6927231\n",
      "positive\n",
      "'uniform' not in training corpus; ignoring.\n",
      "[0.40665978 0.01825259 0.57508767]\n",
      "0.57508767\n",
      "positive\n",
      "'myt' not in training corpus; ignoring.\n",
      "'texan' not in training corpus; ignoring.\n",
      "[0.2128852  0.00193539 0.78517944]\n",
      "0.78517944\n",
      "positive\n",
      "[0.28056914 0.4274719  0.29195893]\n",
      "0.4274719\n",
      "neutral\n",
      "[0.13092759 0.4700031  0.39906922]\n",
      "0.4700031\n",
      "neutral\n",
      "'guilt' not in training corpus; ignoring.\n",
      "'suarez' not in training corpus; ignoring.\n",
      "'punish' not in training corpus; ignoring.\n",
      "[0.27405357 0.54085815 0.18508825]\n",
      "0.54085815\n",
      "neutral\n",
      "[0.38931355 0.06422493 0.5464616 ]\n",
      "0.5464616\n",
      "positive\n",
      "[0.825078   0.06540385 0.10951814]\n",
      "0.825078\n",
      "negative\n",
      "[0.03561444 0.01229869 0.95208687]\n",
      "0.95208687\n",
      "positive\n",
      "'glint' not in training corpus; ignoring.\n",
      "[0.14729905 0.07418225 0.77851874]\n",
      "0.77851874\n",
      "positive\n",
      "'wid' not in training corpus; ignoring.\n",
      "'shobhit' not in training corpus; ignoring.\n",
      "[0.5204352  0.14630651 0.33325827]\n",
      "0.5204352\n",
      "negative\n",
      "'hunger' not in training corpus; ignoring.\n",
      "[0.05530448 0.8624784  0.08221707]\n",
      "0.8624784\n",
      "neutral\n",
      "[0.02155165 0.9308791  0.04756925]\n",
      "0.9308791\n",
      "neutral\n",
      "'connor' not in training corpus; ignoring.\n",
      "'carrick' not in training corpus; ignoring.\n",
      "'garret' not in training corpus; ignoring.\n",
      "[0.57343864 0.19501866 0.23154269]\n",
      "0.57343864\n",
      "negative\n",
      "'ahhhhh' not in training corpus; ignoring.\n",
      "[0.16894773 0.51495653 0.3160958 ]\n",
      "0.51495653\n",
      "neutral\n",
      "[0.00208122 0.00111216 0.9968066 ]\n",
      "0.9968066\n",
      "positive\n",
      "'feather' not in training corpus; ignoring.\n",
      "[0.1079295  0.03882692 0.8532436 ]\n",
      "0.8532436\n",
      "positive\n",
      "'mufc' not in training corpus; ignoring.\n",
      "'mufc' not in training corpus; ignoring.\n",
      "[0.53719056 0.18600143 0.27680793]\n",
      "0.53719056\n",
      "negative\n",
      "[0.00328451 0.96704715 0.02966841]\n",
      "0.96704715\n",
      "neutral\n",
      "'higgin' not in training corpus; ignoring.\n",
      "[0.03555026 0.5498925  0.4145572 ]\n",
      "0.5498925\n",
      "neutral\n",
      "'connor' not in training corpus; ignoring.\n",
      "'relay' not in training corpus; ignoring.\n",
      "[0.12499862 0.68748736 0.18751398]\n",
      "0.68748736\n",
      "neutral\n",
      "'client' not in training corpus; ignoring.\n",
      "'analys' not in training corpus; ignoring.\n",
      "'housem' not in training corpus; ignoring.\n",
      "[0.27927762 0.44799423 0.2727281 ]\n",
      "0.44799423\n",
      "neutral\n",
      "'undisput' not in training corpus; ignoring.\n",
      "[0.09655073 0.83356166 0.0698876 ]\n",
      "0.83356166\n",
      "neutral\n",
      "'smthing' not in training corpus; ignoring.\n",
      "[0.77750033 0.0145564  0.20794323]\n",
      "0.77750033\n",
      "negative\n",
      "'playig' not in training corpus; ignoring.\n",
      "[0.10509001 0.7990962  0.09581371]\n",
      "0.7990962\n",
      "neutral\n",
      "[0.6839882  0.31164697 0.00436482]\n",
      "0.6839882\n",
      "negative\n",
      "[0.16244204 0.1020922  0.73546576]\n",
      "0.73546576\n",
      "positive\n",
      "'ticketmast' not in training corpus; ignoring.\n",
      "[0.90202016 0.03336124 0.06461862]\n",
      "0.90202016\n",
      "negative\n",
      "[0.12603648 0.07711363 0.7968499 ]\n",
      "0.7968499\n",
      "positive\n",
      "[0.10969488 0.4799434  0.41036168]\n",
      "0.4799434\n",
      "neutral\n",
      "[0.6949464  0.04229376 0.26275977]\n",
      "0.6949464\n",
      "negative\n",
      "[0.1258902  0.61140907 0.26270074]\n",
      "0.61140907\n",
      "neutral\n",
      "'aerial' not in training corpus; ignoring.\n",
      "[0.19261467 0.49157602 0.31580934]\n",
      "0.49157602\n",
      "neutral\n",
      "'irrit' not in training corpus; ignoring.\n",
      "[0.00215555 0.02703159 0.9708128 ]\n",
      "0.9708128\n",
      "positive\n",
      "'wildwood' not in training corpus; ignoring.\n",
      "[0.29977795 0.30716723 0.3930548 ]\n",
      "0.3930548\n",
      "positive\n",
      "[0.18838136 0.56541187 0.24620683]\n",
      "0.56541187\n",
      "neutral\n",
      "'burma' not in training corpus; ignoring.\n",
      "'bbc' not in training corpus; ignoring.\n",
      "[0.40239155 0.5222491  0.07535935]\n",
      "0.5222491\n",
      "neutral\n",
      "'disabl' not in training corpus; ignoring.\n",
      "[4.2543197e-05 2.8921920e-06 9.9995458e-01]\n",
      "0.9999546\n",
      "positive\n",
      "[0.3630119  0.01698314 0.620005  ]\n",
      "0.620005\n",
      "positive\n",
      "[0.2789431  0.49264464 0.22841223]\n",
      "0.49264464\n",
      "neutral\n",
      "[0.25496817 0.4321648  0.31286705]\n",
      "0.4321648\n",
      "neutral\n",
      "[0.10514536 0.7201874  0.17466709]\n",
      "0.7201874\n",
      "neutral\n",
      "[0.01156533 0.03768373 0.95075095]\n",
      "0.95075095\n",
      "positive\n",
      "[0.01449249 0.04092053 0.944587  ]\n",
      "0.944587\n",
      "positive\n",
      "'landmark' not in training corpus; ignoring.\n",
      "[0.13404071 0.6252085  0.24075082]\n",
      "0.6252085\n",
      "neutral\n",
      "[0.9144312  0.01947119 0.06609768]\n",
      "0.9144312\n",
      "negative\n",
      "'signific' not in training corpus; ignoring.\n",
      "[0.03768205 0.31401587 0.64830214]\n",
      "0.64830214\n",
      "positive\n",
      "[0.05356778 0.61025697 0.33617532]\n",
      "0.61025697\n",
      "neutral\n",
      "[0.14075305 0.2950848  0.56416214]\n",
      "0.56416214\n",
      "positive\n",
      "[0.0771734  0.79249316 0.1303335 ]\n",
      "0.79249316\n",
      "neutral\n",
      "[0.5209266  0.35440952 0.12466382]\n",
      "0.5209266\n",
      "negative\n",
      "[0.18731232 0.7687561  0.04393157]\n",
      "0.7687561\n",
      "neutral\n",
      "'fave' not in training corpus; ignoring.\n",
      "[0.12120987 0.1888178  0.6899723 ]\n",
      "0.6899723\n",
      "positive\n",
      "'queasi' not in training corpus; ignoring.\n",
      "[0.12665494 0.62160736 0.2517377 ]\n",
      "0.62160736\n",
      "neutral\n",
      "[0.08034649 0.3678749  0.55177855]\n",
      "0.55177855\n",
      "positive\n",
      "[0.14802915 0.40280187 0.44916892]\n",
      "0.44916892\n",
      "positive\n",
      "[0.09857055 0.38513154 0.516298  ]\n",
      "0.516298\n",
      "positive\n",
      "[0.15970713 0.04443371 0.7958591 ]\n",
      "0.7958591\n",
      "positive\n",
      "[0.00661222 0.77662784 0.2167599 ]\n",
      "0.77662784\n",
      "neutral\n",
      "'kane' not in training corpus; ignoring.\n",
      "'leverag' not in training corpus; ignoring.\n",
      "[0.20319453 0.45302403 0.34378147]\n",
      "0.45302403\n",
      "neutral\n",
      "[0.15718724 0.35078302 0.49202967]\n",
      "0.49202967\n",
      "positive\n",
      "'nydn' not in training corpus; ignoring.\n",
      "[0.96765053 0.0095902  0.0227592 ]\n",
      "0.96765053\n",
      "negative\n",
      "'serpong' not in training corpus; ignoring.\n",
      "[0.03090476 0.24519202 0.72390324]\n",
      "0.72390324\n",
      "positive\n",
      "[0.5618481  0.2582844  0.17986749]\n",
      "0.5618481\n",
      "negative\n",
      "'geniu' not in training corpus; ignoring.\n",
      "[0.22121453 0.09813567 0.6806499 ]\n",
      "0.6806499\n",
      "positive\n",
      "[0.01069243 0.70829046 0.28101718]\n",
      "0.70829046\n",
      "neutral\n",
      "[0.0831682  0.3686372  0.54819465]\n",
      "0.54819465\n",
      "positive\n",
      "'benghazi' not in training corpus; ignoring.\n",
      "[0.89526904 0.0860113  0.01871967]\n",
      "0.89526904\n",
      "negative\n",
      "[0.01257512 0.00520286 0.982222  ]\n",
      "0.982222\n",
      "positive\n",
      "[0.03271738 0.00828495 0.9589977 ]\n",
      "0.9589977\n",
      "positive\n",
      "'ivi' not in training corpus; ignoring.\n",
      "[0.3427725  0.582063   0.07516445]\n",
      "0.582063\n",
      "neutral\n",
      "'motor' not in training corpus; ignoring.\n",
      "'vehicl' not in training corpus; ignoring.\n",
      "[0.03017546 0.9686669  0.00115765]\n",
      "0.9686669\n",
      "neutral\n",
      "'saigon' not in training corpus; ignoring.\n",
      "[0.00318866 0.87183285 0.12497845]\n",
      "0.87183285\n",
      "neutral\n",
      "[0.03580545 0.01761975 0.94657475]\n",
      "0.94657475\n",
      "positive\n",
      "[6.4097688e-04 7.1430078e-04 9.9864477e-01]\n",
      "0.99864477\n",
      "positive\n",
      "'notttt' not in training corpus; ignoring.\n",
      "[0.04079643 0.37601122 0.5831924 ]\n",
      "0.5831924\n",
      "positive\n",
      "[0.29934308 0.5956204  0.1050365 ]\n",
      "0.5956204\n",
      "neutral\n",
      "'wcw' not in training corpus; ignoring.\n",
      "[0.0699864  0.8749129  0.05510069]\n",
      "0.8749129\n",
      "neutral\n",
      "'re' not in training corpus; ignoring.\n",
      "[0.8989755  0.04926167 0.05176291]\n",
      "0.8989755\n",
      "negative\n",
      "'sensation' not in training corpus; ignoring.\n",
      "'harrel' not in training corpus; ignoring.\n",
      "[0.3521168  0.47985703 0.16802624]\n",
      "0.47985703\n",
      "neutral\n",
      "'mutter' not in training corpus; ignoring.\n",
      "[0.6892997  0.06792094 0.24277937]\n",
      "0.6892997\n",
      "negative\n",
      "[0.42295858 0.4023813  0.17466001]\n",
      "0.42295858\n",
      "negative\n",
      "'wrom' not in training corpus; ignoring.\n",
      "[4.2917119e-08 9.1842914e-08 9.9999988e-01]\n",
      "0.9999999\n",
      "positive\n",
      "'allianc' not in training corpus; ignoring.\n",
      "'lieberman' not in training corpus; ignoring.\n",
      "'automat' not in training corpus; ignoring.\n",
      "[0.15917446 0.5354882  0.30533737]\n",
      "0.5354882\n",
      "neutral\n",
      "[0.02812917 0.00728687 0.964584  ]\n",
      "0.964584\n",
      "positive\n",
      "'ibb' not in training corpus; ignoring.\n",
      "[0.15110323 0.8153679  0.03352894]\n",
      "0.8153679\n",
      "neutral\n",
      "'xempr' not in training corpus; ignoring.\n",
      "'ngaung' not in training corpus; ignoring.\n",
      "'kip' not in training corpus; ignoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1297     0.5223184  0.34798166]\n",
      "0.5223184\n",
      "neutral\n",
      "'diva' not in training corpus; ignoring.\n",
      "[0.34637022 0.5607979  0.09283193]\n",
      "0.5607979\n",
      "neutral\n",
      "[0.45581457 0.48343864 0.06074685]\n",
      "0.48343864\n",
      "neutral\n",
      "'craig' not in training corpus; ignoring.\n",
      "'expens' not in training corpus; ignoring.\n",
      "[0.25591475 0.57494175 0.1691436 ]\n",
      "0.57494175\n",
      "neutral\n",
      "'scruff' not in training corpus; ignoring.\n",
      "[0.7746327  0.09346231 0.13190497]\n",
      "0.7746327\n",
      "negative\n",
      "[0.32166067 0.45550102 0.2228383 ]\n",
      "0.45550102\n",
      "neutral\n",
      "[0.02766052 0.7745229  0.19781661]\n",
      "0.7745229\n",
      "neutral\n",
      "[0.11848723 0.0952857  0.78622705]\n",
      "0.78622705\n",
      "positive\n",
      "'tommi' not in training corpus; ignoring.\n",
      "'baauer' not in training corpus; ignoring.\n",
      "[0.3006956  0.628477   0.07082739]\n",
      "0.628477\n",
      "neutral\n",
      "'arch' not in training corpus; ignoring.\n",
      "[0.15747903 0.21548311 0.6270379 ]\n",
      "0.6270379\n",
      "positive\n",
      "'starland' not in training corpus; ignoring.\n",
      "[0.06308942 0.7314038  0.20550683]\n",
      "0.7314038\n",
      "neutral\n",
      "'botch' not in training corpus; ignoring.\n",
      "'ag' not in training corpus; ignoring.\n",
      "[0.6309832 0.2205377 0.1484792]\n",
      "0.6309832\n",
      "negative\n",
      "'jare' not in training corpus; ignoring.\n",
      "[0.01202923 0.9742367  0.01373406]\n",
      "0.9742367\n",
      "neutral\n",
      "[0.24413356 0.33434498 0.42152146]\n",
      "0.42152146\n",
      "positive\n",
      "[0.02379534 0.61193776 0.3642669 ]\n",
      "0.61193776\n",
      "neutral\n",
      "[0.4247925  0.0074186  0.56778896]\n",
      "0.56778896\n",
      "positive\n",
      "'sphere' not in training corpus; ignoring.\n",
      "[0.29463622 0.6499268  0.05543701]\n",
      "0.6499268\n",
      "neutral\n",
      "[0.06661003 0.9051544  0.02823555]\n",
      "0.9051544\n",
      "neutral\n",
      "[0.09555086 0.02952468 0.8749245 ]\n",
      "0.8749245\n",
      "positive\n",
      "[0.02465264 0.02450011 0.9508472 ]\n",
      "0.9508472\n",
      "positive\n",
      "'ipercoop' not in training corpus; ignoring.\n",
      "'piazza' not in training corpus; ignoring.\n",
      "'lodi' not in training corpus; ignoring.\n",
      "'carrefour' not in training corpus; ignoring.\n",
      "[0.8215641  0.13458303 0.04385289]\n",
      "0.8215641\n",
      "negative\n",
      "[0.09497405 0.3691586  0.53586733]\n",
      "0.53586733\n",
      "positive\n",
      "'gsp' not in training corpus; ignoring.\n",
      "[0.30358475 0.28363997 0.4127753 ]\n",
      "0.4127753\n",
      "positive\n",
      "[0.04052695 0.00219039 0.9572827 ]\n",
      "0.9572827\n",
      "positive\n",
      "[0.0715553  0.72998714 0.19845752]\n",
      "0.72998714\n",
      "neutral\n",
      "[0.16240548 0.13573621 0.70185834]\n",
      "0.70185834\n",
      "positive\n",
      "[0.9376134  0.04620106 0.01618554]\n",
      "0.9376134\n",
      "negative\n",
      "'brittani' not in training corpus; ignoring.\n",
      "[0.9002307  0.03952738 0.06024197]\n",
      "0.9002307\n",
      "negative\n",
      "[0.1193571 0.2570992 0.6235437]\n",
      "0.6235437\n",
      "positive\n",
      "[0.29165652 0.65029067 0.05805273]\n",
      "0.65029067\n",
      "neutral\n",
      "[0.00478731 0.9665355  0.02867718]\n",
      "0.9665355\n",
      "neutral\n",
      "[0.06535832 0.01541465 0.91922706]\n",
      "0.91922706\n",
      "positive\n",
      "'sanford' not in training corpus; ignoring.\n",
      "[0.3186958  0.6201228  0.06118143]\n",
      "0.6201228\n",
      "neutral\n",
      "'belat' not in training corpus; ignoring.\n",
      "'throwback' not in training corpus; ignoring.\n",
      "'uniform' not in training corpus; ignoring.\n",
      "[0.6395198  0.09933496 0.26114523]\n",
      "0.6395198\n",
      "negative\n",
      "'hve' not in training corpus; ignoring.\n",
      "[0.40365008 0.07752876 0.5188211 ]\n",
      "0.5188211\n",
      "positive\n",
      "'repair' not in training corpus; ignoring.\n",
      "'elderli' not in training corpus; ignoring.\n",
      "'cathod' not in training corpus; ignoring.\n",
      "'tube' not in training corpus; ignoring.\n",
      "[0.22171672 0.74695253 0.03133069]\n",
      "0.74695253\n",
      "neutral\n",
      "[0.3722045  0.30775303 0.32004246]\n",
      "0.3722045\n",
      "negative\n",
      "'scold' not in training corpus; ignoring.\n",
      "'crotchal' not in training corpus; ignoring.\n",
      "[0.49934468 0.44429117 0.05636415]\n",
      "0.49934468\n",
      "negative\n",
      "'hardbal' not in training corpus; ignoring.\n",
      "[0.55483365 0.06761909 0.3775473 ]\n",
      "0.55483365\n",
      "negative\n",
      "'uniform' not in training corpus; ignoring.\n",
      "'reunit' not in training corpus; ignoring.\n",
      "[0.21887061 0.49875024 0.28237915]\n",
      "0.49875024\n",
      "neutral\n",
      "'accred' not in training corpus; ignoring.\n",
      "'rebt' not in training corpus; ignoring.\n",
      "[0.76959085 0.16169809 0.06871107]\n",
      "0.76959085\n",
      "negative\n",
      "'maxwel' not in training corpus; ignoring.\n",
      "'lmfaoooo' not in training corpus; ignoring.\n",
      "[9.9232602e-01 5.2268396e-04 7.1513350e-03]\n",
      "0.992326\n",
      "negative\n",
      "'yahoo' not in training corpus; ignoring.\n",
      "'cincinnati' not in training corpus; ignoring.\n",
      "[0.1404296  0.35539186 0.5041786 ]\n",
      "0.5041786\n",
      "positive\n",
      "[0.0205893 0.0365125 0.9428982]\n",
      "0.9428982\n",
      "positive\n",
      "'sunjennif' not in training corpus; ignoring.\n",
      "[0.05769206 0.8770882  0.06521973]\n",
      "0.8770882\n",
      "neutral\n",
      "'gazett' not in training corpus; ignoring.\n",
      "[0.12114292 0.6536435  0.22521363]\n",
      "0.6536435\n",
      "neutral\n",
      "'wkh' not in training corpus; ignoring.\n",
      "[0.15222527 0.24992415 0.59785056]\n",
      "0.59785056\n",
      "positive\n",
      "[0.05696374 0.00995598 0.93308026]\n",
      "0.93308026\n",
      "positive\n",
      "'sigh' not in training corpus; ignoring.\n",
      "'relief' not in training corpus; ignoring.\n",
      "[0.1626702 0.2718596 0.5654702]\n",
      "0.5654702\n",
      "positive\n",
      "'shi' not in training corpus; ignoring.\n",
      "'glizzi' not in training corpus; ignoring.\n",
      "'bouta' not in training corpus; ignoring.\n",
      "[0.7169726  0.08646435 0.19656311]\n",
      "0.7169726\n",
      "negative\n",
      "'express' not in training corpus; ignoring.\n",
      "[0.05911441 0.83738166 0.10350401]\n",
      "0.83738166\n",
      "neutral\n",
      "'sutra' not in training corpus; ignoring.\n",
      "[0.10880246 0.5429776  0.34822   ]\n",
      "0.5429776\n",
      "neutral\n",
      "'hebrew' not in training corpus; ignoring.\n",
      "[0.45392892 0.32142422 0.22464688]\n",
      "0.45392892\n",
      "negative\n",
      "[0.05215835 0.43927372 0.508568  ]\n",
      "0.508568\n",
      "positive\n",
      "[0.04044216 0.17649858 0.7830593 ]\n",
      "0.7830593\n",
      "positive\n",
      "[0.6001896  0.29203796 0.1077724 ]\n",
      "0.6001896\n",
      "negative\n",
      "[0.5704469  0.28558108 0.14397204]\n",
      "0.5704469\n",
      "negative\n",
      "[0.2297775  0.5264651  0.24375732]\n",
      "0.5264651\n",
      "neutral\n",
      "'suisham' not in training corpus; ignoring.\n",
      "[0.80269736 0.07311957 0.12418308]\n",
      "0.80269736\n",
      "negative\n",
      "'serdang' not in training corpus; ignoring.\n",
      "[0.0914476  0.67455846 0.23399399]\n",
      "0.67455846\n",
      "neutral\n",
      "[0.03512524 0.95582783 0.00904692]\n",
      "0.95582783\n",
      "neutral\n",
      "[0.11938187 0.75066924 0.1299489 ]\n",
      "0.75066924\n",
      "neutral\n",
      "'krystal' not in training corpus; ignoring.\n",
      "[0.08168831 0.26475415 0.65355754]\n",
      "0.65355754\n",
      "positive\n",
      "'playhous' not in training corpus; ignoring.\n",
      "[0.0066936  0.2265925  0.76671386]\n",
      "0.76671386\n",
      "positive\n",
      "[0.84375656 0.10767375 0.04856975]\n",
      "0.84375656\n",
      "negative\n",
      "'bantam' not in training corpus; ignoring.\n",
      "[0.09169262 0.11334286 0.79496455]\n",
      "0.79496455\n",
      "positive\n",
      "[0.15764515 0.8308337  0.01152118]\n",
      "0.8308337\n",
      "neutral\n",
      "'surprisingli' not in training corpus; ignoring.\n",
      "[0.31680027 0.5315382  0.15166155]\n",
      "0.5315382\n",
      "neutral\n",
      "'leadoff' not in training corpus; ignoring.\n",
      "'zaharion' not in training corpus; ignoring.\n",
      "[0.3407909  0.57198846 0.08722071]\n",
      "0.57198846\n",
      "neutral\n",
      "'mwr' not in training corpus; ignoring.\n",
      "[0.07544855 0.79686725 0.12768415]\n",
      "0.79686725\n",
      "neutral\n",
      "'analys' not in training corpus; ignoring.\n",
      "[0.30760568 0.16574527 0.5266491 ]\n",
      "0.5266491\n",
      "positive\n",
      "[0.3331215  0.6159808  0.05089768]\n",
      "0.6159808\n",
      "neutral\n",
      "'traffic' not in training corpus; ignoring.\n",
      "[0.11367447 0.03908609 0.8472395 ]\n",
      "0.8472395\n",
      "positive\n",
      "[0.00339215 0.93501306 0.0615948 ]\n",
      "0.93501306\n",
      "neutral\n",
      "'jmu' not in training corpus; ignoring.\n",
      "'gmu' not in training corpus; ignoring.\n",
      "[0.23659067 0.29845452 0.46495476]\n",
      "0.46495476\n",
      "positive\n",
      "[0.99339926 0.00486392 0.00173682]\n",
      "0.99339926\n",
      "negative\n",
      "[0.13529916 0.6802265  0.18447426]\n",
      "0.6802265\n",
      "neutral\n",
      "[0.06732761 0.86538714 0.06728522]\n",
      "0.86538714\n",
      "neutral\n",
      "[0.48727208 0.2711952  0.24153271]\n",
      "0.48727208\n",
      "negative\n",
      "[0.09810285 0.02157789 0.88031924]\n",
      "0.88031924\n",
      "positive\n",
      "'alphabet' not in training corpus; ignoring.\n",
      "[0.42137504 0.26962316 0.30900177]\n",
      "0.42137504\n",
      "negative\n",
      "[0.6259218  0.22219275 0.15188545]\n",
      "0.6259218\n",
      "negative\n",
      "[0.33616686 0.5605163  0.1033168 ]\n",
      "0.5605163\n",
      "neutral\n",
      "[0.04105554 0.22637203 0.73257244]\n",
      "0.73257244\n",
      "positive\n",
      "'brintey' not in training corpus; ignoring.\n",
      "[0.00279745 0.00538965 0.99181294]\n",
      "0.99181294\n",
      "positive\n",
      "'homeless' not in training corpus; ignoring.\n",
      "'granddaught' not in training corpus; ignoring.\n",
      "'bucksadschool' not in training corpus; ignoring.\n",
      "[9.3436253e-04 2.1612606e-04 9.9884951e-01]\n",
      "0.9988495\n",
      "positive\n",
      "[0.00903278 0.00587925 0.98508793]\n",
      "0.98508793\n",
      "positive\n",
      "[0.34681058 0.11688726 0.5363021 ]\n",
      "0.5363021\n",
      "positive\n",
      "'uc' not in training corpus; ignoring.\n",
      "[0.03241882 0.01430644 0.9532747 ]\n",
      "0.9532747\n",
      "positive\n",
      "'unnecessarili' not in training corpus; ignoring.\n",
      "[0.02662028 0.00687518 0.9665045 ]\n",
      "0.9665045\n",
      "positive\n",
      "[0.34872118 0.22788021 0.4233986 ]\n",
      "0.4233986\n",
      "positive\n",
      "[0.20536765 0.14529637 0.649336  ]\n",
      "0.649336\n",
      "positive\n",
      "[0.00906528 0.03244839 0.9584863 ]\n",
      "0.9584863\n",
      "positive\n",
      "[0.34361836 0.36576456 0.2906171 ]\n",
      "0.36576456\n",
      "neutral\n",
      "'widow' not in training corpus; ignoring.\n",
      "[0.22960399 0.13692795 0.6334681 ]\n",
      "0.6334681\n",
      "positive\n",
      "[0.44883996 0.4823879  0.06877207]\n",
      "0.4823879\n",
      "neutral\n",
      "[0.28572732 0.43417323 0.28009942]\n",
      "0.43417323\n",
      "neutral\n",
      "'trinamool' not in training corpus; ignoring.\n",
      "[0.2834674  0.5670855  0.14944708]\n",
      "0.5670855\n",
      "neutral\n",
      "'booooooo' not in training corpus; ignoring.\n",
      "[0.19577025 0.0643798  0.7398499 ]\n",
      "0.7398499\n",
      "positive\n",
      "[0.69952285 0.2909648  0.00951237]\n",
      "0.69952285\n",
      "negative\n",
      "'everli' not in training corpus; ignoring.\n",
      "[0.48874545 0.49880838 0.01244622]\n",
      "0.49880838\n",
      "neutral\n",
      "'halt' not in training corpus; ignoring.\n",
      "[0.08350018 0.8707746  0.04572527]\n",
      "0.8707746\n",
      "neutral\n",
      "[0.00764    0.00500874 0.98735124]\n",
      "0.98735124\n",
      "positive\n",
      "'hermosa' not in training corpus; ignoring.\n",
      "[0.15155098 0.82180583 0.02664315]\n",
      "0.82180583\n",
      "neutral\n",
      "[0.141646   0.48973298 0.36862105]\n",
      "0.48973298\n",
      "neutral\n",
      "'couldv' not in training corpus; ignoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4598798  0.01962503 0.52049524]\n",
      "0.52049524\n",
      "positive\n",
      "'giddi' not in training corpus; ignoring.\n",
      "[0.92094207 0.04009508 0.03896282]\n",
      "0.92094207\n",
      "negative\n",
      "'mattock' not in training corpus; ignoring.\n",
      "'rifl' not in training corpus; ignoring.\n",
      "[0.73031473 0.26540884 0.00427648]\n",
      "0.73031473\n",
      "negative\n",
      "[0.02647969 0.45318046 0.5203398 ]\n",
      "0.5203398\n",
      "positive\n",
      "'nyg' not in training corpus; ignoring.\n",
      "'turnov' not in training corpus; ignoring.\n",
      "[0.22331323 0.18632294 0.5903638 ]\n",
      "0.5903638\n",
      "positive\n",
      "'cinemonkey' not in training corpus; ignoring.\n",
      "[0.00206996 0.00727983 0.9906502 ]\n",
      "0.9906502\n",
      "positive\n",
      "[0.31422323 0.01995743 0.6658194 ]\n",
      "0.6658194\n",
      "positive\n",
      "'resist' not in training corpus; ignoring.\n",
      "[0.8937903  0.10042822 0.0057815 ]\n",
      "0.8937903\n",
      "negative\n",
      "'capricorn' not in training corpus; ignoring.\n",
      "'sider' not in training corpus; ignoring.\n",
      "[0.4793632  0.11083973 0.40979707]\n",
      "0.4793632\n",
      "negative\n",
      "[0.38411042 0.11236222 0.50352734]\n",
      "0.50352734\n",
      "positive\n",
      "[0.10373279 0.8616102  0.03465702]\n",
      "0.8616102\n",
      "neutral\n",
      "'redneck' not in training corpus; ignoring.\n",
      "'blare' not in training corpus; ignoring.\n",
      "[0.58090305 0.32097936 0.09811765]\n",
      "0.58090305\n",
      "negative\n",
      "[0.18689908 0.32696086 0.4861401 ]\n",
      "0.4861401\n",
      "positive\n",
      "'doncast' not in training corpus; ignoring.\n",
      "'groin' not in training corpus; ignoring.\n",
      "[0.01441403 0.95198953 0.03359636]\n",
      "0.95198953\n",
      "neutral\n",
      "[0.03630237 0.05794729 0.9057504 ]\n",
      "0.9057504\n",
      "positive\n",
      "'trill' not in training corpus; ignoring.\n",
      "'nake' not in training corpus; ignoring.\n",
      "[0.2824862  0.01691786 0.700596  ]\n",
      "0.700596\n",
      "positive\n",
      "'fundiment' not in training corpus; ignoring.\n",
      "[0.31847554 0.03442178 0.64710265]\n",
      "0.64710265\n",
      "positive\n",
      "[0.26833227 0.4729963  0.25867146]\n",
      "0.4729963\n",
      "neutral\n",
      "[0.25522488 0.14529113 0.59948397]\n",
      "0.59948397\n",
      "positive\n",
      "[0.5128282  0.43624046 0.05093138]\n",
      "0.5128282\n",
      "negative\n",
      "[0.8564104  0.01952484 0.12406489]\n",
      "0.8564104\n",
      "negative\n",
      "'dialogu' not in training corpus; ignoring.\n",
      "[0.42581233 0.2927208  0.28146684]\n",
      "0.42581233\n",
      "negative\n",
      "[0.3408093  0.5473899  0.11180083]\n",
      "0.5473899\n",
      "neutral\n",
      "'pmln' not in training corpus; ignoring.\n",
      "'pti' not in training corpus; ignoring.\n",
      "[0.00635483 0.9036611  0.08998413]\n",
      "0.9036611\n",
      "neutral\n",
      "'mcgeezer' not in training corpus; ignoring.\n",
      "[0.31326237 0.61960906 0.06712864]\n",
      "0.61960906\n",
      "neutral\n",
      "[0.44464326 0.48969337 0.0656634 ]\n",
      "0.48969337\n",
      "neutral\n",
      "[0.01656985 0.5554871  0.4279431 ]\n",
      "0.5554871\n",
      "neutral\n",
      "[0.0978948  0.8806517  0.02145353]\n",
      "0.8806517\n",
      "neutral\n",
      "[1.3569517e-03 1.4717382e-05 9.9862838e-01]\n",
      "0.9986284\n",
      "positive\n",
      "[0.42313743 0.4777277  0.09913488]\n",
      "0.4777277\n",
      "neutral\n",
      "[0.00158111 0.00230435 0.9961145 ]\n",
      "0.9961145\n",
      "positive\n",
      "[0.09417216 0.7126914  0.19313642]\n",
      "0.7126914\n",
      "neutral\n",
      "[0.15778513 0.7849375  0.05727736]\n",
      "0.7849375\n",
      "neutral\n",
      "'eurovis' not in training corpus; ignoring.\n",
      "[0.0785556  0.50959766 0.41184685]\n",
      "0.50959766\n",
      "neutral\n",
      "[0.68447906 0.00951815 0.3060028 ]\n",
      "0.68447906\n",
      "negative\n",
      "'fausto' not in training corpus; ignoring.\n",
      "'carmona' not in training corpus; ignoring.\n",
      "[0.46263647 0.30919263 0.22817092]\n",
      "0.46263647\n",
      "negative\n",
      "[0.18254986 0.7171151  0.1003351 ]\n",
      "0.7171151\n",
      "neutral\n",
      "[4.2420499e-05 1.1125677e-05 9.9994648e-01]\n",
      "0.9999465\n",
      "positive\n",
      "[0.75234133 0.00525858 0.24240011]\n",
      "0.75234133\n",
      "negative\n",
      "[0.498159   0.16010396 0.34173703]\n",
      "0.498159\n",
      "negative\n",
      "[0.00194612 0.03386865 0.9641852 ]\n",
      "0.9641852\n",
      "positive\n",
      "'hondo' not in training corpus; ignoring.\n",
      "'endur' not in training corpus; ignoring.\n",
      "'customari' not in training corpus; ignoring.\n",
      "'wipeout' not in training corpus; ignoring.\n",
      "[0.4459597  0.46925774 0.08478261]\n",
      "0.46925774\n",
      "neutral\n",
      "[0.00807487 0.00412079 0.9878043 ]\n",
      "0.9878043\n",
      "positive\n",
      "'outburst' not in training corpus; ignoring.\n",
      "[0.13623881 0.22162051 0.6421406 ]\n",
      "0.6421406\n",
      "positive\n",
      "'gulf' not in training corpus; ignoring.\n",
      "[0.43902072 0.53727895 0.02370033]\n",
      "0.53727895\n",
      "neutral\n",
      "[0.3880218  0.36944652 0.24253173]\n",
      "0.3880218\n",
      "negative\n",
      "[0.00331687 0.02428588 0.9723973 ]\n",
      "0.9723973\n",
      "positive\n",
      "'giuliana' not in training corpus; ignoring.\n",
      "'rancic' not in training corpus; ignoring.\n",
      "'cancer' not in training corpus; ignoring.\n",
      "'awar' not in training corpus; ignoring.\n",
      "[0.0017613  0.7544771  0.24376167]\n",
      "0.7544771\n",
      "neutral\n",
      "'each' not in training corpus; ignoring.\n",
      "[0.03285549 0.93844795 0.02869657]\n",
      "0.93844795\n",
      "neutral\n",
      "'ef' not in training corpus; ignoring.\n",
      "'uv' not in training corpus; ignoring.\n",
      "'filter' not in training corpus; ignoring.\n",
      "'hood' not in training corpus; ignoring.\n",
      "'accessori' not in training corpus; ignoring.\n",
      "[0.3805402  0.5404383  0.07902148]\n",
      "0.5404383\n",
      "neutral\n",
      "[0.3251689  0.11351397 0.56131715]\n",
      "0.56131715\n",
      "positive\n",
      "[0.50298405 0.447299   0.04971701]\n",
      "0.50298405\n",
      "negative\n",
      "'favreau' not in training corpus; ignoring.\n",
      "'spice' not in training corpus; ignoring.\n",
      "[0.03550561 0.8763199  0.08817454]\n",
      "0.8763199\n",
      "neutral\n",
      "'finebaum' not in training corpus; ignoring.\n",
      "[0.4412638  0.5287445  0.02999172]\n",
      "0.5287445\n",
      "neutral\n",
      "'suav' not in training corpus; ignoring.\n",
      "'fucker' not in training corpus; ignoring.\n",
      "[0.2624833  0.5418172  0.19569953]\n",
      "0.5418172\n",
      "neutral\n",
      "[0.00356497 0.00526761 0.9911675 ]\n",
      "0.9911675\n",
      "positive\n",
      "'upnsmok' not in training corpus; ignoring.\n",
      "[0.00231666 0.02938092 0.9683024 ]\n",
      "0.9683024\n",
      "positive\n",
      "'faze' not in training corpus; ignoring.\n",
      "[0.638755   0.27863404 0.08261099]\n",
      "0.638755\n",
      "negative\n",
      "[0.12164185 0.6956806  0.18267757]\n",
      "0.6956806\n",
      "neutral\n",
      "[0.1939676  0.7110714  0.09496099]\n",
      "0.7110714\n",
      "neutral\n",
      "'aesop' not in training corpus; ignoring.\n",
      "'jon' not in training corpus; ignoring.\n",
      "'cyhi' not in training corpus; ignoring.\n",
      "'sleepin' not in training corpus; ignoring.\n",
      "[0.6052067  0.12630877 0.26848444]\n",
      "0.6052067\n",
      "negative\n",
      "'blackwel' not in training corpus; ignoring.\n",
      "[0.38158292 0.15001835 0.46839872]\n",
      "0.46839872\n",
      "positive\n",
      "[0.79573447 0.10748718 0.09677837]\n",
      "0.79573447\n",
      "negative\n",
      "'naww' not in training corpus; ignoring.\n",
      "[0.031381   0.00533784 0.96328115]\n",
      "0.96328115\n",
      "positive\n",
      "[0.4049081  0.55555856 0.03953333]\n",
      "0.55555856\n",
      "neutral\n",
      "'kena' not in training corpus; ignoring.\n",
      "'chong' not in training corpus; ignoring.\n",
      "[0.1221414  0.62513924 0.25271934]\n",
      "0.62513924\n",
      "neutral\n",
      "'bbc' not in training corpus; ignoring.\n",
      "'ukg' not in training corpus; ignoring.\n",
      "'cameo' not in training corpus; ignoring.\n",
      "[0.02211842 0.9659747  0.01190692]\n",
      "0.9659747\n",
      "neutral\n",
      "[0.2076786  0.68162555 0.1106959 ]\n",
      "0.68162555\n",
      "neutral\n",
      "[0.25406277 0.7265317  0.01940556]\n",
      "0.7265317\n",
      "neutral\n",
      "'suryakumar' not in training corpus; ignoring.\n",
      "'yadav' not in training corpus; ignoring.\n",
      "[0.02430175 0.89262396 0.0830743 ]\n",
      "0.89262396\n",
      "neutral\n",
      "[0.20869926 0.7009465  0.09035426]\n",
      "0.7009465\n",
      "neutral\n",
      "[0.00344085 0.0071909  0.98936826]\n",
      "0.98936826\n",
      "positive\n",
      "'creosot' not in training corpus; ignoring.\n",
      "'tini' not in training corpus; ignoring.\n",
      "'tempah' not in training corpus; ignoring.\n",
      "[0.15970488 0.30907285 0.5312223 ]\n",
      "0.5312223\n",
      "positive\n",
      "[0.4567924  0.09165595 0.45155168]\n",
      "0.4567924\n",
      "negative\n",
      "[0.6098465  0.0296844  0.36046907]\n",
      "0.6098465\n",
      "negative\n",
      "'sync' not in training corpus; ignoring.\n",
      "[0.56974393 0.42315915 0.00709692]\n",
      "0.56974393\n",
      "negative\n",
      "[0.05223453 0.86855143 0.0792141 ]\n",
      "0.86855143\n",
      "neutral\n",
      "[0.04180505 0.09540517 0.86278975]\n",
      "0.86278975\n",
      "positive\n",
      "[0.6488481  0.00286785 0.34828407]\n",
      "0.6488481\n",
      "negative\n",
      "'welp' not in training corpus; ignoring.\n",
      "[0.06370817 0.8760668  0.060225  ]\n",
      "0.8760668\n",
      "neutral\n",
      "'rashid' not in training corpus; ignoring.\n",
      "[0.2124569  0.76631814 0.02122495]\n",
      "0.76631814\n",
      "neutral\n",
      "'picnic' not in training corpus; ignoring.\n",
      "'moshpit' not in training corpus; ignoring.\n",
      "'datsun' not in training corpus; ignoring.\n",
      "[0.90595424 0.06930205 0.02474365]\n",
      "0.90595424\n",
      "negative\n",
      "[0.3100618 0.5344629 0.1554752]\n",
      "0.5344629\n",
      "neutral\n",
      "[0.4012373  0.2790643  0.31969842]\n",
      "0.4012373\n",
      "negative\n",
      "'lbjsc' not in training corpus; ignoring.\n",
      "[0.09253807 0.67872    0.2287419 ]\n",
      "0.67872\n",
      "neutral\n",
      "[0.0698342  0.63947994 0.29068595]\n",
      "0.63947994\n",
      "neutral\n",
      "[0.05030749 0.00625484 0.94343764]\n",
      "0.94343764\n",
      "positive\n",
      "'swim' not in training corpus; ignoring.\n",
      "[0.06434494 0.00105273 0.9346023 ]\n",
      "0.9346023\n",
      "positive\n",
      "[0.21766526 0.49531773 0.28701705]\n",
      "0.49531773\n",
      "neutral\n",
      "'ogunribido' not in training corpus; ignoring.\n",
      "'lpc' not in training corpus; ignoring.\n",
      "[7.2140014e-04 9.9737871e-01 1.9000047e-03]\n",
      "0.9973787\n",
      "neutral\n",
      "'vb' not in training corpus; ignoring.\n",
      "[0.11451893 0.08961326 0.79586786]\n",
      "0.79586786\n",
      "positive\n",
      "[0.2055711  0.2986255  0.49580336]\n",
      "0.49580336\n",
      "positive\n",
      "[0.65667135 0.18487276 0.1584559 ]\n",
      "0.65667135\n",
      "negative\n",
      "[0.44442004 0.5114415  0.04413847]\n",
      "0.5114415\n",
      "neutral\n",
      "'huum' not in training corpus; ignoring.\n",
      "'tunisia' not in training corpus; ignoring.\n",
      "'huum' not in training corpus; ignoring.\n",
      "'nialler' not in training corpus; ignoring.\n",
      "[0.11309501 0.6320504  0.25485462]\n",
      "0.6320504\n",
      "neutral\n",
      "'canvas' not in training corpus; ignoring.\n",
      "[3.5010281e-03 3.2564107e-04 9.9617332e-01]\n",
      "0.9961733\n",
      "positive\n",
      "'uefa' not in training corpus; ignoring.\n",
      "[0.2905503  0.55575246 0.1536972 ]\n",
      "0.55575246\n",
      "neutral\n",
      "[0.69100255 0.26740465 0.04159285]\n",
      "0.69100255\n",
      "negative\n",
      "'xhosa' not in training corpus; ignoring.\n",
      "'morvit' not in training corpus; ignoring.\n",
      "[0.74200267 0.2119525  0.0460448 ]\n",
      "0.74200267\n",
      "negative\n",
      "[0.11285677 0.05761769 0.8295256 ]\n",
      "0.8295256\n",
      "positive\n",
      "'scam' not in training corpus; ignoring.\n",
      "'scam' not in training corpus; ignoring.\n",
      "[0.45120737 0.43051508 0.11827758]\n",
      "0.45120737\n",
      "negative\n",
      "'decim' not in training corpus; ignoring.\n",
      "'bullpen' not in training corpus; ignoring.\n",
      "[0.07924421 0.52585477 0.39490095]\n",
      "0.52585477\n",
      "neutral\n",
      "'childhood' not in training corpus; ignoring.\n",
      "[4.9318252e-03 8.4700657e-04 9.9422121e-01]\n",
      "0.9942212\n",
      "positive\n",
      "[0.65309817 0.27456784 0.07233406]\n",
      "0.65309817\n",
      "negative\n",
      "'mumford' not in training corpus; ignoring.\n",
      "'onsal' not in training corpus; ignoring.\n",
      "[0.07532318 0.5578669  0.36681002]\n",
      "0.5578669\n",
      "neutral\n",
      "'luna' not in training corpus; ignoring.\n",
      "[0.23362796 0.08148924 0.6848827 ]\n",
      "0.6848827\n",
      "positive\n",
      "[0.60085714 0.16816576 0.2309771 ]\n",
      "0.60085714\n",
      "negative\n",
      "[0.11446645 0.30887762 0.5766559 ]\n",
      "0.5766559\n",
      "positive\n",
      "[0.06068543 0.77086884 0.16844569]\n",
      "0.77086884\n",
      "neutral\n",
      "'ooosh' not in training corpus; ignoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00557251 0.00358178 0.99084574]\n",
      "0.99084574\n",
      "positive\n",
      "[0.9138394  0.04927601 0.0368846 ]\n",
      "0.9138394\n",
      "negative\n",
      "[0.3515111  0.35124665 0.29724225]\n",
      "0.3515111\n",
      "negative\n",
      "[0.00232925 0.42229503 0.57537574]\n",
      "0.57537574\n",
      "positive\n",
      "[0.00437722 0.2319871  0.76363564]\n",
      "0.76363564\n",
      "positive\n",
      "[0.06793592 0.22821878 0.70384526]\n",
      "0.70384526\n",
      "positive\n",
      "'unreleas' not in training corpus; ignoring.\n",
      "'likeeeeeeeee' not in training corpus; ignoring.\n",
      "[0.1659856  0.05331225 0.7807022 ]\n",
      "0.7807022\n",
      "positive\n",
      "[0.26198292 0.39393198 0.34408513]\n",
      "0.39393198\n",
      "neutral\n",
      "'anaheim' not in training corpus; ignoring.\n",
      "[0.00563719 0.8537558  0.14060704]\n",
      "0.8537558\n",
      "neutral\n",
      "[1.0872284e-02 1.9940619e-04 9.8892832e-01]\n",
      "0.9889283\n",
      "positive\n",
      "[0.02014099 0.8307443  0.14911461]\n",
      "0.8307443\n",
      "neutral\n",
      "[0.05164672 0.9032271  0.04512621]\n",
      "0.9032271\n",
      "neutral\n",
      "[0.38569394 0.2003578  0.41394827]\n",
      "0.41394827\n",
      "positive\n",
      "'jeffersonvil' not in training corpus; ignoring.\n",
      "[0.00159013 0.8708576  0.1275523 ]\n",
      "0.8708576\n",
      "neutral\n",
      "'mccormick' not in training corpus; ignoring.\n",
      "[0.34311366 0.4871827  0.16970359]\n",
      "0.4871827\n",
      "neutral\n",
      "[0.01950755 0.81593466 0.16455774]\n",
      "0.81593466\n",
      "neutral\n",
      "'fx' not in training corpus; ignoring.\n",
      "'sumthin' not in training corpus; ignoring.\n",
      "[0.0713936  0.02329667 0.90530974]\n",
      "0.90530974\n",
      "positive\n",
      "[0.14503796 0.8220672  0.03289478]\n",
      "0.8220672\n",
      "neutral\n",
      "[0.5580944  0.34381053 0.09809517]\n",
      "0.5580944\n",
      "negative\n",
      "[0.17752658 0.81112456 0.01134886]\n",
      "0.81112456\n",
      "neutral\n",
      "[0.411516   0.03879727 0.54968673]\n",
      "0.54968673\n",
      "positive\n",
      "[0.10069016 0.88462055 0.01468938]\n",
      "0.88462055\n",
      "neutral\n",
      "'nye' not in training corpus; ignoring.\n",
      "[0.01554507 0.831429   0.153026  ]\n",
      "0.831429\n",
      "neutral\n",
      "'nasa' not in training corpus; ignoring.\n",
      "'extragalact' not in training corpus; ignoring.\n",
      "'implic' not in training corpus; ignoring.\n",
      "[0.02643854 0.10596756 0.86759394]\n",
      "0.86759394\n",
      "positive\n",
      "[5.5645901e-04 2.1983678e-03 9.9724519e-01]\n",
      "0.9972452\n",
      "positive\n",
      "'mcalest' not in training corpus; ignoring.\n",
      "[0.13223204 0.7665962  0.10117178]\n",
      "0.7665962\n",
      "neutral\n",
      "'drube' not in training corpus; ignoring.\n",
      "'hitter' not in training corpus; ignoring.\n",
      "'fault' not in training corpus; ignoring.\n",
      "[0.15978281 0.06115469 0.77906245]\n",
      "0.77906245\n",
      "positive\n",
      "[0.76524264 0.16982247 0.06493495]\n",
      "0.76524264\n",
      "negative\n",
      "[0.00279011 0.16512337 0.83208656]\n",
      "0.83208656\n",
      "positive\n",
      "[0.06281181 0.05060331 0.8865849 ]\n",
      "0.8865849\n",
      "positive\n",
      "[0.07779518 0.746861   0.17534387]\n",
      "0.746861\n",
      "neutral\n",
      "[0.2786447 0.4281357 0.2932196]\n",
      "0.4281357\n",
      "neutral\n",
      "[0.2967039  0.633182   0.07011414]\n",
      "0.633182\n",
      "neutral\n",
      "'levin' not in training corpus; ignoring.\n",
      "[3.1176187e-02 9.6832609e-01 4.9771072e-04]\n",
      "0.9683261\n",
      "neutral\n",
      "[0.23861013 0.13413718 0.62725264]\n",
      "0.62725264\n",
      "positive\n",
      "[0.05010657 0.13311759 0.81677586]\n",
      "0.81677586\n",
      "positive\n",
      "[0.02088124 0.3924338  0.58668506]\n",
      "0.58668506\n",
      "positive\n",
      "'scenec' not in training corpus; ignoring.\n",
      "'atlanta' not in training corpus; ignoring.\n",
      "'regga' not in training corpus; ignoring.\n",
      "[0.00156642 0.6832067  0.3152269 ]\n",
      "0.6832067\n",
      "neutral\n",
      "[0.60297567 0.01600506 0.3810193 ]\n",
      "0.60297567\n",
      "negative\n",
      "'pound' not in training corpus; ignoring.\n",
      "[0.14077432 0.79844475 0.06078098]\n",
      "0.79844475\n",
      "neutral\n",
      "[0.64583766 0.23696572 0.11719667]\n",
      "0.64583766\n",
      "negative\n",
      "[0.02858719 0.8925562  0.07885665]\n",
      "0.8925562\n",
      "neutral\n",
      "[0.04513506 0.93910617 0.01575874]\n",
      "0.93910617\n",
      "neutral\n",
      "[0.00356497 0.00526761 0.9911675 ]\n",
      "0.9911675\n",
      "positive\n",
      "[0.06661543 0.0732609  0.86012363]\n",
      "0.86012363\n",
      "positive\n",
      "'sociedad' not in training corpus; ignoring.\n",
      "'osauna' not in training corpus; ignoring.\n",
      "[0.31960902 0.2527823  0.42760867]\n",
      "0.42760867\n",
      "positive\n",
      "[0.7649846  0.23001437 0.00500092]\n",
      "0.7649846\n",
      "negative\n",
      "[0.17127857 0.61744785 0.21127354]\n",
      "0.61744785\n",
      "neutral\n",
      "'emerg' not in training corpus; ignoring.\n",
      "[0.76692116 0.20777982 0.02529904]\n",
      "0.76692116\n",
      "negative\n",
      "'racetrack' not in training corpus; ignoring.\n",
      "[0.7802142 0.1273044 0.0924814]\n",
      "0.7802142\n",
      "negative\n",
      "'flyin' not in training corpus; ignoring.\n",
      "'kickin' not in training corpus; ignoring.\n",
      "'fresno' not in training corpus; ignoring.\n",
      "[0.04121105 0.7506356  0.20815337]\n",
      "0.7506356\n",
      "neutral\n",
      "[0.22292458 0.4739098  0.30316564]\n",
      "0.4739098\n",
      "neutral\n",
      "[0.1257497  0.59804344 0.2762069 ]\n",
      "0.59804344\n",
      "neutral\n",
      "[0.02394408 0.91842014 0.05763579]\n",
      "0.91842014\n",
      "neutral\n",
      "'sidelin' not in training corpus; ignoring.\n",
      "[0.53890115 0.35757303 0.10352585]\n",
      "0.53890115\n",
      "negative\n",
      "'colbert' not in training corpus; ignoring.\n",
      "[0.8785201  0.07700388 0.04447596]\n",
      "0.8785201\n",
      "negative\n",
      "[0.12370878 0.10660868 0.7696825 ]\n",
      "0.7696825\n",
      "positive\n",
      "'beckham' not in training corpus; ignoring.\n",
      "'header' not in training corpus; ignoring.\n",
      "[0.29447895 0.61585623 0.08966485]\n",
      "0.61585623\n",
      "neutral\n",
      "'touchdown' not in training corpus; ignoring.\n",
      "[0.32465434 0.65863097 0.01671469]\n",
      "0.65863097\n",
      "neutral\n",
      "'cof' not in training corpus; ignoring.\n",
      "[0.13532351 0.27460486 0.5900716 ]\n",
      "0.5900716\n",
      "positive\n",
      "'kelsey' not in training corpus; ignoring.\n",
      "'grammer' not in training corpus; ignoring.\n",
      "[0.4595335  0.00967801 0.5307885 ]\n",
      "0.5307885\n",
      "positive\n",
      "[5.4365569e-03 2.0872653e-04 9.9435472e-01]\n",
      "0.9943547\n",
      "positive\n",
      "'intimid' not in training corpus; ignoring.\n",
      "[0.936037   0.04878604 0.01517707]\n",
      "0.936037\n",
      "negative\n",
      "[4.4782776e-03 9.2725269e-04 9.9459451e-01]\n",
      "0.9945945\n",
      "positive\n",
      "'carmel' not in training corpus; ignoring.\n",
      "'dtown' not in training corpus; ignoring.\n",
      "[0.03033707 0.03815946 0.9315035 ]\n",
      "0.9315035\n",
      "positive\n",
      "'supersport' not in training corpus; ignoring.\n",
      "'bidvest' not in training corpus; ignoring.\n",
      "'morip' not in training corpus; ignoring.\n",
      "[0.04683955 0.92312634 0.03003407]\n",
      "0.92312634\n",
      "neutral\n",
      "'maldini' not in training corpus; ignoring.\n",
      "[0.44313145 0.45616856 0.10069995]\n",
      "0.45616856\n",
      "neutral\n",
      "'luau' not in training corpus; ignoring.\n",
      "[0.02472592 0.80903023 0.1662438 ]\n",
      "0.80903023\n",
      "neutral\n",
      "[0.0023609  0.9872743  0.01036481]\n",
      "0.9872743\n",
      "neutral\n",
      "[0.5251859  0.3226149  0.15219916]\n",
      "0.5251859\n",
      "negative\n",
      "[0.01069055 0.55321264 0.43609676]\n",
      "0.55321264\n",
      "neutral\n",
      "[0.07624029 0.86136436 0.06239527]\n",
      "0.86136436\n",
      "neutral\n",
      "'nuff' not in training corpus; ignoring.\n",
      "[0.00938272 0.97764015 0.01297712]\n",
      "0.97764015\n",
      "neutral\n",
      "'cube' not in training corpus; ignoring.\n",
      "'epp' not in training corpus; ignoring.\n",
      "'smokey' not in training corpus; ignoring.\n",
      "'worm' not in training corpus; ignoring.\n",
      "[0.05411004 0.21869658 0.7271934 ]\n",
      "0.7271934\n",
      "positive\n",
      "[0.5248845  0.15990677 0.31520867]\n",
      "0.5248845\n",
      "negative\n",
      "[0.02641811 0.00473629 0.9688456 ]\n",
      "0.9688456\n",
      "positive\n",
      "[0.06526213 0.8705481  0.06418973]\n",
      "0.8705481\n",
      "neutral\n",
      "[0.03927964 0.01283655 0.94788384]\n",
      "0.94788384\n",
      "positive\n",
      "[0.03996532 0.8405982  0.1194365 ]\n",
      "0.8405982\n",
      "neutral\n",
      "[0.02697935 0.50483894 0.46818167]\n",
      "0.50483894\n",
      "neutral\n",
      "'oooh' not in training corpus; ignoring.\n",
      "[0.8429573  0.05010839 0.10693427]\n",
      "0.8429573\n",
      "negative\n",
      "'hoffmann' not in training corpus; ignoring.\n",
      "'tisch' not in training corpus; ignoring.\n",
      "[0.04076193 0.60994667 0.34929138]\n",
      "0.60994667\n",
      "neutral\n",
      "'core' not in training corpus; ignoring.\n",
      "'banquet' not in training corpus; ignoring.\n",
      "[0.01981737 0.75264215 0.22754043]\n",
      "0.75264215\n",
      "neutral\n",
      "[0.7086317  0.14794064 0.1434276 ]\n",
      "0.7086317\n",
      "negative\n",
      "'ahaha' not in training corpus; ignoring.\n",
      "[0.40503207 0.39160526 0.20336258]\n",
      "0.40503207\n",
      "negative\n",
      "[0.65405273 0.02914844 0.31679884]\n",
      "0.65405273\n",
      "negative\n",
      "[0.0180752  0.02727812 0.95464665]\n",
      "0.95464665\n",
      "positive\n",
      "'beeni' not in training corpus; ignoring.\n",
      "'echostag' not in training corpus; ignoring.\n",
      "'hu' not in training corpus; ignoring.\n",
      "'yardfest' not in training corpus; ignoring.\n",
      "'afterparti' not in training corpus; ignoring.\n",
      "[0.02603544 0.65076226 0.32320234]\n",
      "0.65076226\n",
      "neutral\n",
      "[0.07182196 0.88212746 0.04605057]\n",
      "0.88212746\n",
      "neutral\n",
      "'dawg' not in training corpus; ignoring.\n",
      "'tendi' not in training corpus; ignoring.\n",
      "[0.1346044  0.56076676 0.30462882]\n",
      "0.56076676\n",
      "neutral\n",
      "'tourist' not in training corpus; ignoring.\n",
      "[0.07252015 0.01219768 0.9152822 ]\n",
      "0.9152822\n",
      "positive\n",
      "'clinton' not in training corpus; ignoring.\n",
      "[0.5601825  0.34220153 0.09761592]\n",
      "0.5601825\n",
      "negative\n",
      "[0.24716042 0.49337375 0.2594658 ]\n",
      "0.49337375\n",
      "neutral\n",
      "[0.04618752 0.38660634 0.56720614]\n",
      "0.56720614\n",
      "positive\n",
      "'frenchman' not in training corpus; ignoring.\n",
      "[0.13392033 0.6752387  0.19084089]\n",
      "0.6752387\n",
      "neutral\n",
      "'satellit' not in training corpus; ignoring.\n",
      "'muscat' not in training corpus; ignoring.\n",
      "'thundershow' not in training corpus; ignoring.\n",
      "[0.16049911 0.743252   0.09624896]\n",
      "0.743252\n",
      "neutral\n",
      "'dee' not in training corpus; ignoring.\n",
      "'dee' not in training corpus; ignoring.\n",
      "'visual' not in training corpus; ignoring.\n",
      "'dee' not in training corpus; ignoring.\n",
      "'dee' not in training corpus; ignoring.\n",
      "[0.08778439 0.8195951  0.09262056]\n",
      "0.8195951\n",
      "neutral\n",
      "'myanmar' not in training corpus; ignoring.\n",
      "'yangon' not in training corpus; ignoring.\n",
      "'visa' not in training corpus; ignoring.\n",
      "[0.27661875 0.37661391 0.3467673 ]\n",
      "0.37661391\n",
      "neutral\n",
      "'ulyss' not in training corpus; ignoring.\n",
      "[0.44840306 0.4227149  0.12888205]\n",
      "0.44840306\n",
      "negative\n",
      "[0.25521412 0.5017939  0.242992  ]\n",
      "0.5017939\n",
      "neutral\n",
      "'ahah' not in training corpus; ignoring.\n",
      "[0.05535613 0.16788754 0.77675635]\n",
      "0.77675635\n",
      "positive\n",
      "'crossov' not in training corpus; ignoring.\n",
      "'istanbul' not in training corpus; ignoring.\n",
      "[0.03277699 0.8973007  0.06992219]\n",
      "0.8973007\n",
      "neutral\n",
      "'bedolla' not in training corpus; ignoring.\n",
      "'skater' not in training corpus; ignoring.\n",
      "'boyz' not in training corpus; ignoring.\n",
      "[0.19937654 0.23739529 0.5632282 ]\n",
      "0.5632282\n",
      "positive\n",
      "'fyi' not in training corpus; ignoring.\n",
      "'ladybug' not in training corpus; ignoring.\n",
      "[0.61676574 0.3278391  0.05539513]\n",
      "0.61676574\n",
      "negative\n",
      "[0.9934097  0.00369531 0.00289502]\n",
      "0.9934097\n",
      "negative\n",
      "'stalker' not in training corpus; ignoring.\n",
      "[0.517449   0.33750308 0.14504787]\n",
      "0.517449\n",
      "negative\n",
      "'texan' not in training corpus; ignoring.\n",
      "[0.8918292  0.0975311  0.01063977]\n",
      "0.8918292\n",
      "negative\n",
      "'pledg' not in training corpus; ignoring.\n",
      "[0.46536845 0.08403968 0.4505919 ]\n",
      "0.46536845\n",
      "negative\n",
      "[0.66412276 0.20342445 0.13245276]\n",
      "0.66412276\n",
      "negative\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24851327 0.02190602 0.7295807 ]\n",
      "0.7295807\n",
      "positive\n",
      "'weaken' not in training corpus; ignoring.\n",
      "'ghana' not in training corpus; ignoring.\n",
      "'visa' not in training corpus; ignoring.\n",
      "[0.28806582 0.3172766  0.39465758]\n",
      "0.39465758\n",
      "positive\n",
      "'sweetteapumpkinpi' not in training corpus; ignoring.\n",
      "[0.2043285  0.76596445 0.02970712]\n",
      "0.76596445\n",
      "neutral\n",
      "[0.7462649  0.10479212 0.14894305]\n",
      "0.7462649\n",
      "negative\n",
      "'wouldnt' not in training corpus; ignoring.\n",
      "'hearsay' not in training corpus; ignoring.\n",
      "[0.13715732 0.78437537 0.07846735]\n",
      "0.78437537\n",
      "neutral\n",
      "[0.11412064 0.80261636 0.08326299]\n",
      "0.80261636\n",
      "neutral\n",
      "'refund' not in training corpus; ignoring.\n",
      "'tout' not in training corpus; ignoring.\n",
      "[0.3056554  0.39148653 0.3028581 ]\n",
      "0.39148653\n",
      "neutral\n",
      "'calm' not in training corpus; ignoring.\n",
      "[0.2052503  0.08837041 0.7063793 ]\n",
      "0.7063793\n",
      "positive\n",
      "'visa' not in training corpus; ignoring.\n",
      "[0.00822062 0.86385024 0.12792914]\n",
      "0.86385024\n",
      "neutral\n",
      "[0.1496991 0.8315879 0.018713 ]\n",
      "0.8315879\n",
      "neutral\n",
      "[0.17897321 0.807066   0.01396071]\n",
      "0.807066\n",
      "neutral\n",
      "[0.01015993 0.87833345 0.11150664]\n",
      "0.87833345\n",
      "neutral\n",
      "[0.23421896 0.73061025 0.03517081]\n",
      "0.73061025\n",
      "neutral\n",
      "[0.14284638 0.8235345  0.03361915]\n",
      "0.8235345\n",
      "neutral\n",
      "[0.07455679 0.9092245  0.01621876]\n",
      "0.9092245\n",
      "neutral\n",
      "'novememb' not in training corpus; ignoring.\n",
      "[0.07352331 0.77366763 0.15280905]\n",
      "0.77366763\n",
      "neutral\n",
      "[0.02740874 0.9073459  0.06524529]\n",
      "0.9073459\n",
      "neutral\n",
      "'ht' not in training corpus; ignoring.\n",
      "[0.10861003 0.81933856 0.07205134]\n",
      "0.81933856\n",
      "neutral\n",
      "[0.6272533  0.18195857 0.19078809]\n",
      "0.6272533\n",
      "negative\n",
      "'woosahhhh' not in training corpus; ignoring.\n",
      "[0.07344837 0.31859657 0.6079551 ]\n",
      "0.6079551\n",
      "positive\n",
      "[0.8897268  0.02696921 0.08330388]\n",
      "0.8897268\n",
      "negative\n",
      "'nix' not in training corpus; ignoring.\n",
      "[0.08471297 0.78906375 0.12622327]\n",
      "0.78906375\n",
      "neutral\n",
      "[0.4962638  0.46235576 0.04138052]\n",
      "0.4962638\n",
      "negative\n",
      "[0.00778565 0.07888407 0.91333026]\n",
      "0.91333026\n",
      "positive\n",
      "[0.00194805 0.6401507  0.35790128]\n",
      "0.6401507\n",
      "neutral\n",
      "[0.05715188 0.0999668  0.8428813 ]\n",
      "0.8428813\n",
      "positive\n",
      "[2.6329337e-03 5.5796938e-04 9.9680907e-01]\n",
      "0.99680907\n",
      "positive\n",
      "[0.00819202 0.01900625 0.9728017 ]\n",
      "0.9728017\n",
      "positive\n",
      "[0.11186079 0.52770174 0.3604375 ]\n",
      "0.52770174\n",
      "neutral\n",
      "[0.05396042 0.54731923 0.39872032]\n",
      "0.54731923\n",
      "neutral\n",
      "[0.03594478 0.08680313 0.87725204]\n",
      "0.87725204\n",
      "positive\n",
      "[0.17194058 0.4467529  0.38130653]\n",
      "0.4467529\n",
      "neutral\n",
      "[0.11111767 0.14755258 0.74132967]\n",
      "0.74132967\n",
      "positive\n",
      "'buran' not in training corpus; ignoring.\n",
      "'mayo' not in training corpus; ignoring.\n",
      "[0.04510625 0.9145726  0.0403211 ]\n",
      "0.9145726\n",
      "neutral\n",
      "'dutch' not in training corpus; ignoring.\n",
      "'tapet' not in training corpus; ignoring.\n",
      "[0.12486523 0.7079618  0.16717303]\n",
      "0.7079618\n",
      "neutral\n",
      "[0.01531028 0.73783094 0.24685873]\n",
      "0.73783094\n",
      "neutral\n",
      "'bmi' not in training corpus; ignoring.\n",
      "'reign' not in training corpus; ignoring.\n",
      "[0.09173992 0.73955125 0.16870882]\n",
      "0.73955125\n",
      "neutral\n",
      "'vta' not in training corpus; ignoring.\n",
      "'ledesma' not in training corpus; ignoring.\n",
      "'ztra' not in training corpus; ignoring.\n",
      "[0.6364772  0.09602024 0.26750264]\n",
      "0.6364772\n",
      "negative\n",
      "[0.02853978 0.00774325 0.963717  ]\n",
      "0.963717\n",
      "positive\n",
      "'bummer' not in training corpus; ignoring.\n",
      "[0.00512914 0.0014092  0.9934616 ]\n",
      "0.9934616\n",
      "positive\n",
      "[0.09824854 0.61318845 0.288563  ]\n",
      "0.61318845\n",
      "neutral\n",
      "[0.01551435 0.00432583 0.9801599 ]\n",
      "0.9801599\n",
      "positive\n",
      "[0.2949858  0.5639719  0.14104232]\n",
      "0.5639719\n",
      "neutral\n",
      "'mj' not in training corpus; ignoring.\n",
      "[0.37038735 0.33605203 0.2935607 ]\n",
      "0.37038735\n",
      "negative\n",
      "'eid' not in training corpus; ignoring.\n",
      "'afoot' not in training corpus; ignoring.\n",
      "'interior' not in training corpus; ignoring.\n",
      "'eid' not in training corpus; ignoring.\n",
      "[0.0041816  0.96524173 0.03057669]\n",
      "0.96524173\n",
      "neutral\n",
      "'zylona' not in training corpus; ignoring.\n",
      "'hookah' not in training corpus; ignoring.\n",
      "[0.02822181 0.09938487 0.8723933 ]\n",
      "0.8723933\n",
      "positive\n",
      "[0.25758567 0.06015634 0.682258  ]\n",
      "0.682258\n",
      "positive\n",
      "'ly' not in training corpus; ignoring.\n",
      "'heli' not in training corpus; ignoring.\n",
      "'bbq' not in training corpus; ignoring.\n",
      "[0.06158757 0.75987065 0.1785418 ]\n",
      "0.75987065\n",
      "neutral\n",
      "[0.07361806 0.8566624  0.06971949]\n",
      "0.8566624\n",
      "neutral\n",
      "'incheon' not in training corpus; ignoring.\n",
      "[0.16603166 0.039201   0.7947673 ]\n",
      "0.7947673\n",
      "positive\n",
      "[0.3801509  0.600838   0.01901111]\n",
      "0.600838\n",
      "neutral\n",
      "[3.6056202e-02 3.1721088e-04 9.6362656e-01]\n",
      "0.96362656\n",
      "positive\n",
      "'onert' not in training corpus; ignoring.\n",
      "[0.8395963  0.00303491 0.15736873]\n",
      "0.8395963\n",
      "negative\n",
      "'sore' not in training corpus; ignoring.\n",
      "[0.0393468  0.24493332 0.7157199 ]\n",
      "0.7157199\n",
      "positive\n",
      "[0.01811143 0.78958786 0.19230075]\n",
      "0.78958786\n",
      "neutral\n",
      "'socialist' not in training corpus; ignoring.\n",
      "'liar' not in training corpus; ignoring.\n",
      "'frighten' not in training corpus; ignoring.\n",
      "[0.13520977 0.08010233 0.7846878 ]\n",
      "0.7846878\n",
      "positive\n",
      "'liberalis' not in training corpus; ignoring.\n",
      "'visa' not in training corpus; ignoring.\n",
      "'liberalis' not in training corpus; ignoring.\n",
      "[0.04666485 0.9096806  0.04365461]\n",
      "0.9096806\n",
      "neutral\n",
      "[0.34681794 0.43344134 0.21974067]\n",
      "0.43344134\n",
      "neutral\n",
      "'disturb' not in training corpus; ignoring.\n",
      "[0.5353671  0.21470547 0.24992746]\n",
      "0.5353671\n",
      "negative\n",
      "'lbpv' not in training corpus; ignoring.\n",
      "[0.4006089  0.29133347 0.30805758]\n",
      "0.4006089\n",
      "negative\n",
      "'xf' not in training corpus; ignoring.\n",
      "[0.04897259 0.87315077 0.07787668]\n",
      "0.87315077\n",
      "neutral\n",
      "'glasgow' not in training corpus; ignoring.\n",
      "[0.00567951 0.002335   0.99198544]\n",
      "0.99198544\n",
      "positive\n",
      "[1.6450228e-02 9.0430060e-04 9.8264551e-01]\n",
      "0.9826455\n",
      "positive\n",
      "[0.1499105  0.6988973  0.15119216]\n",
      "0.6988973\n",
      "neutral\n",
      "'homeless' not in training corpus; ignoring.\n",
      "[0.3504618  0.6032391  0.04629904]\n",
      "0.6032391\n",
      "neutral\n",
      "'talib' not in training corpus; ignoring.\n",
      "'re' not in training corpus; ignoring.\n",
      "[0.07474712 0.8120867  0.11316615]\n",
      "0.8120867\n",
      "neutral\n",
      "[0.02740145 0.9247113  0.04788732]\n",
      "0.9247113\n",
      "neutral\n",
      "[0.83249    0.02512074 0.14238922]\n",
      "0.83249\n",
      "negative\n",
      "'usf' not in training corpus; ignoring.\n",
      "[0.153186  0.7318913 0.1149227]\n",
      "0.7318913\n",
      "neutral\n",
      "[0.33124232 0.14102349 0.52773416]\n",
      "0.52773416\n",
      "positive\n",
      "[0.08086389 0.21996935 0.6991667 ]\n",
      "0.6991667\n",
      "positive\n",
      "[0.01214691 0.98184973 0.00600334]\n",
      "0.98184973\n",
      "neutral\n",
      "[0.03274154 0.8436188  0.12363964]\n",
      "0.8436188\n",
      "neutral\n",
      "'twinke' not in training corpus; ignoring.\n",
      "[0.07704457 0.0136172  0.90933824]\n",
      "0.90933824\n",
      "positive\n",
      "[0.08235546 0.73519343 0.18245105]\n",
      "0.73519343\n",
      "neutral\n",
      "[0.4717587 0.4814151 0.0468262]\n",
      "0.4814151\n",
      "neutral\n",
      "'strictli' not in training corpus; ignoring.\n",
      "'gunplay' not in training corpus; ignoring.\n",
      "'pistol' not in training corpus; ignoring.\n",
      "[0.60721993 0.3183683  0.07441176]\n",
      "0.60721993\n",
      "negative\n",
      "[0.40487906 0.500388   0.09473289]\n",
      "0.500388\n",
      "neutral\n",
      "[0.9385818  0.03231388 0.02910434]\n",
      "0.9385818\n",
      "negative\n",
      "'sherlock' not in training corpus; ignoring.\n",
      "[0.98215723 0.00866164 0.00918107]\n",
      "0.98215723\n",
      "negative\n",
      "'wha' not in training corpus; ignoring.\n",
      "[0.8717879  0.09093612 0.03727598]\n",
      "0.8717879\n",
      "negative\n",
      "[0.05640678 0.49020353 0.45338973]\n",
      "0.49020353\n",
      "neutral\n",
      "[0.02720192 0.5867491  0.38604903]\n",
      "0.5867491\n",
      "neutral\n",
      "[0.19602469 0.5356746  0.26830074]\n",
      "0.5356746\n",
      "neutral\n",
      "'kniteforc' not in training corpus; ignoring.\n",
      "'boxset' not in training corpus; ignoring.\n",
      "[0.08291857 0.3590846  0.55799687]\n",
      "0.55799687\n",
      "positive\n",
      "[0.24225403 0.26746702 0.49027893]\n",
      "0.49027893\n",
      "positive\n",
      "[0.57190263 0.17950252 0.24859482]\n",
      "0.57190263\n",
      "negative\n",
      "[0.10674286 0.02040732 0.8728498 ]\n",
      "0.8728498\n",
      "positive\n",
      "[0.5507663  0.2158849  0.23334886]\n",
      "0.5507663\n",
      "negative\n",
      "'foggiest' not in training corpus; ignoring.\n",
      "[0.42589518 0.09707158 0.4770332 ]\n",
      "0.4770332\n",
      "positive\n",
      "[0.16313322 0.23028079 0.60658604]\n",
      "0.60658604\n",
      "positive\n",
      "'lollipop' not in training corpus; ignoring.\n",
      "'chainsaw' not in training corpus; ignoring.\n",
      "[0.20601785 0.44628027 0.34770185]\n",
      "0.44628027\n",
      "neutral\n",
      "'stink' not in training corpus; ignoring.\n",
      "'rif' not in training corpus; ignoring.\n",
      "[0.45572206 0.4980573  0.04622057]\n",
      "0.4980573\n",
      "neutral\n",
      "'pbb' not in training corpus; ignoring.\n",
      "[0.02442034 0.9090559  0.06652368]\n",
      "0.9090559\n",
      "neutral\n",
      "'actress' not in training corpus; ignoring.\n",
      "'ell' not in training corpus; ignoring.\n",
      "'octavia' not in training corpus; ignoring.\n",
      "[0.03617808 0.8038474  0.15997455]\n",
      "0.8038474\n",
      "neutral\n",
      "'scheme' not in training corpus; ignoring.\n",
      "'blacksburg' not in training corpus; ignoring.\n",
      "[0.63603    0.28826028 0.07570975]\n",
      "0.63603\n",
      "negative\n",
      "[0.3514033 0.268363  0.3802337]\n",
      "0.3802337\n",
      "positive\n",
      "[0.2726243  0.58715636 0.14021927]\n",
      "0.58715636\n",
      "neutral\n",
      "[0.01343794 0.88037765 0.10618445]\n",
      "0.88037765\n",
      "neutral\n",
      "[0.19761229 0.19281036 0.60957736]\n",
      "0.60957736\n",
      "positive\n",
      "'wasteland' not in training corpus; ignoring.\n",
      "[0.5520568  0.18058506 0.2673582 ]\n",
      "0.5520568\n",
      "negative\n",
      "'tamp' not in training corpus; ignoring.\n",
      "[0.16515775 0.63092107 0.20392118]\n",
      "0.63092107\n",
      "neutral\n",
      "[0.02736341 0.7060917  0.2665449 ]\n",
      "0.7060917\n",
      "neutral\n",
      "[0.6142938  0.17999752 0.20570865]\n",
      "0.6142938\n",
      "negative\n",
      "'arni' not in training corpus; ignoring.\n",
      "[0.00269199 0.00349429 0.99381375]\n",
      "0.99381375\n",
      "positive\n",
      "[0.6606444  0.04037275 0.29898283]\n",
      "0.6606444\n",
      "negative\n",
      "'squee' not in training corpus; ignoring.\n",
      "'usurp' not in training corpus; ignoring.\n",
      "[0.7450668  0.04641989 0.20851335]\n",
      "0.7450668\n",
      "negative\n",
      "'sim' not in training corpus; ignoring.\n",
      "'weapon' not in training corpus; ignoring.\n",
      "[0.28117412 0.6305264  0.0882995 ]\n",
      "0.6305264\n",
      "neutral\n",
      "'burnley' not in training corpus; ignoring.\n",
      "[0.01280986 0.98564106 0.00154914]\n",
      "0.98564106\n",
      "neutral\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7300664  0.23997001 0.02996357]\n",
      "0.7300664\n",
      "negative\n",
      "[0.0300735  0.9555399  0.01438663]\n",
      "0.9555399\n",
      "neutral\n",
      "[0.01979536 0.13177094 0.8484337 ]\n",
      "0.8484337\n",
      "positive\n",
      "'aye' not in training corpus; ignoring.\n",
      "'comcast' not in training corpus; ignoring.\n",
      "[0.01104131 0.86222416 0.12673458]\n",
      "0.86222416\n",
      "neutral\n",
      "'testdriv' not in training corpus; ignoring.\n",
      "[0.12224948 0.84736454 0.03038603]\n",
      "0.84736454\n",
      "neutral\n",
      "[0.41004086 0.46835783 0.12160139]\n",
      "0.46835783\n",
      "neutral\n",
      "'pretenti' not in training corpus; ignoring.\n",
      "[0.05436927 0.0783672  0.8672635 ]\n",
      "0.8672635\n",
      "positive\n",
      "[0.3375145  0.41775438 0.24473113]\n",
      "0.41775438\n",
      "neutral\n",
      "[0.5161397  0.36312154 0.1207388 ]\n",
      "0.5161397\n",
      "negative\n",
      "'fourteen' not in training corpus; ignoring.\n",
      "[0.61907196 0.20319057 0.17773749]\n",
      "0.61907196\n",
      "negative\n",
      "'zag' not in training corpus; ignoring.\n",
      "[0.4342977  0.52968735 0.03601496]\n",
      "0.52968735\n",
      "neutral\n",
      "[0.03471872 0.39579654 0.5694848 ]\n",
      "0.5694848\n",
      "positive\n",
      "'advic' not in training corpus; ignoring.\n",
      "'juddmont' not in training corpus; ignoring.\n",
      "[0.00280591 0.92063653 0.07655758]\n",
      "0.92063653\n",
      "neutral\n",
      "'squint' not in training corpus; ignoring.\n",
      "[0.18348756 0.66836154 0.14815088]\n",
      "0.66836154\n",
      "neutral\n",
      "[0.11927734 0.72388387 0.15683873]\n",
      "0.72388387\n",
      "neutral\n",
      "'qualcomm' not in training corpus; ignoring.\n",
      "[0.90463674 0.00420878 0.09115438]\n",
      "0.90463674\n",
      "negative\n",
      "[0.74075    0.21325842 0.04599161]\n",
      "0.74075\n",
      "negative\n",
      "'vintag' not in training corpus; ignoring.\n",
      "[0.48115322 0.39831668 0.12053016]\n",
      "0.48115322\n",
      "negative\n",
      "[0.7177228  0.01601423 0.26626307]\n",
      "0.7177228\n",
      "negative\n",
      "[0.00514473 0.02350857 0.9713467 ]\n",
      "0.9713467\n",
      "positive\n",
      "'shanney' not in training corpus; ignoring.\n",
      "[0.00356129 0.01963979 0.9767989 ]\n",
      "0.9767989\n",
      "positive\n",
      "[0.27003723 0.6809174  0.04904538]\n",
      "0.6809174\n",
      "neutral\n",
      "[0.34681642 0.10022327 0.5529603 ]\n",
      "0.5529603\n",
      "positive\n",
      "'spleader' not in training corpus; ignoring.\n",
      "[0.01515636 0.14347214 0.8413715 ]\n",
      "0.8413715\n",
      "positive\n",
      "[0.1780846  0.5566925  0.26522294]\n",
      "0.5566925\n",
      "neutral\n",
      "[0.3630835  0.6220024  0.01491397]\n",
      "0.6220024\n",
      "neutral\n",
      "'lattimor' not in training corpus; ignoring.\n",
      "[0.10020501 0.79698604 0.10280897]\n",
      "0.79698604\n",
      "neutral\n",
      "[0.10436791 0.31712982 0.5785023 ]\n",
      "0.5785023\n",
      "positive\n",
      "'sparrow' not in training corpus; ignoring.\n",
      "'collabor' not in training corpus; ignoring.\n",
      "'rivoli' not in training corpus; ignoring.\n",
      "'dakota' not in training corpus; ignoring.\n",
      "[0.15377924 0.8398498  0.00637093]\n",
      "0.8398498\n",
      "neutral\n",
      "[0.51776224 0.03919942 0.44303828]\n",
      "0.51776224\n",
      "negative\n",
      "'whisper' not in training corpus; ignoring.\n",
      "[0.21775657 0.07579909 0.7064443 ]\n",
      "0.7064443\n",
      "positive\n",
      "[0.07429706 0.08417374 0.8415292 ]\n",
      "0.8415292\n",
      "positive\n",
      "[0.0076325  0.82759786 0.1647696 ]\n",
      "0.82759786\n",
      "neutral\n",
      "'asa' not in training corpus; ignoring.\n",
      "[0.00203509 0.987936   0.01002892]\n",
      "0.987936\n",
      "neutral\n",
      "[0.16194852 0.72866344 0.10938799]\n",
      "0.72866344\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "que=[]\n",
    "for i in test_x:\n",
    "    #evalSentence = input('Input a sentence to be evaluated, or Enter to quit: ')\n",
    "    evalSentence=i\n",
    "    if len(evalSentence) == 0:\n",
    "        break\n",
    "\n",
    "    # format your input for the neural net\n",
    "    testArr = convert_text_to_index_array(evalSentence)\n",
    "    inp = tokenizer.sequences_to_matrix([testArr], mode='binary')\n",
    "    # predict which bucket your input belongs in\n",
    "    pred = model.predict(inp)\n",
    "    k=np.amax(pred[0])\n",
    "    print(pred[0])\n",
    "    print(k)\n",
    "    ind=list(pred[0]).index(k)\n",
    "    print(labels[ind])\n",
    "    que.append(ind)\n",
    "    # and print it for the humons\n",
    "    #print(\"%s sentiment; %f%% confidence\" % (labels[np.argmax(pred)], pred[0][np.argmax(pred)] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5796847635726795\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "notp=0\n",
    "notn=0\n",
    "notq=0\n",
    "for i in range(len(que)):\n",
    "    if que[i]==test_y[i]:\n",
    "        count+=1\n",
    "print(count/len(que))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf=pd.DataFrame(data=data,columns=(\"types\",\"posts\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'neutral', 'positive']\n"
     ]
    }
   ],
   "source": [
    "newdf=labelencode(newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6936\n",
      "6936\n"
     ]
    }
   ],
   "source": [
    "nposts=np.array(newdf['posts'])\n",
    "nlabels=np.array(newdf['typeint'])\n",
    "print(len(nposts))\n",
    "print(len(nlabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf['posts'] = newdf['posts'].apply(lambda x: x.lower())\n",
    "\n",
    "newdf['posts'] = newdf['posts'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fatures = 5000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(newdf['posts'].values)\n",
    "X = tokenizer.texts_to_sequences(newdf['posts'].values)\n",
    "X = sequence.pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 190, 128)          640000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 591       \n",
      "=================================================================\n",
      "Total params: 895,391\n",
      "Trainable params: 895,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "#model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5548, 190) (5548, 3)\n",
      "(1388, 190) (1388, 3)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(newdf['types']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      " - 34s - loss: 0.9483 - acc: 0.5442\n",
      "Epoch 2/7\n",
      " - 38s - loss: 0.6723 - acc: 0.7186\n",
      "Epoch 3/7\n",
      " - 40s - loss: 0.4609 - acc: 0.8198\n",
      "Epoch 4/7\n",
      " - 38s - loss: 0.3383 - acc: 0.8700\n",
      "Epoch 5/7\n",
      " - 39s - loss: 0.2544 - acc: 0.9093\n",
      "Epoch 6/7\n",
      " - 38s - loss: 0.1830 - acc: 0.9349\n",
      "Epoch 7/7\n",
      " - 39s - loss: 0.1413 - acc: 0.9537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f79b6b1a898>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(X_train, Y_train, epochs = 7, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 1.64\n",
      "acc: 0.62\n"
     ]
    }
   ],
   "source": [
    "\n",
    "score,acc=(model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size))\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
