{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import nltk.data\n",
    "import csv\n",
    "from nltk.stem.porter import *\n",
    "pd.options.mode.chained_assignment = None\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numpy import array as arr\n",
    "from numpy import argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "         types                                              posts\n",
      "0     negative  Iranian general says Israel's Iron Dome can't ...\n",
      "1     positive  with J Davlar 11th. Main rivals are team Polan...\n",
      "2     negative  Talking about ACT's &amp;&amp; SAT's, deciding...\n",
      "3     negative  They may have a SuperBowl in Dallas, but Dalla...\n",
      "4      neutral  Im bringing the monster load of candy tomorrow...\n",
      "5      neutral  Apple software, retail chiefs out in overhaul:...\n",
      "6     positive  @oluoch @victor_otti @kunjand I just watched i...\n",
      "7      neutral  #Livewire Nadal confirmed for Mexican Open in ...\n",
      "8     positive  @MsSheLahY I didnt want to just pop up... but ...\n",
      "9      neutral  @Alyoup005 @addicted2haley hmmmm  November is ...\n",
      "10     neutral  #Iran US delisting MKO from global terrorists ...\n",
      "11    positive  Good Morning Becky ! Thursday is going to be F...\n",
      "12     neutral  Expect light-moderate rains over E. Visayas; C...\n",
      "13    positive  One ticket left for the @49ers game tomorrow! ...\n",
      "14    negative  AFC away fans on Saturday. All this stuff abou...\n",
      "15     neutral  Game 1 of the NLCS and a rematch of the NFC Ch...\n",
      "16    positive  Never start working on your dreams and goals t...\n",
      "17    positive  @TheFFAddict I had Vick and Flacco, needed an ...\n",
      "18    positive  Looks like Andy the Android may have had a lit...\n",
      "19    positive  @APGPhoto oooh nice .. Tis tempting to go up t...\n",
      "20     neutral  BLACK FRIDAY Huge Saving Aerial View of a City...\n",
      "21    negative  @MelmurMel @PBandJenelley_1 @vl_delp_ham_ Jene...\n",
      "22     neutral  Mohamed Morsi, Egypt's Muslim Brotherhood pres...\n",
      "23     neutral  C'mon Avila! You just got tagged out by a guy ...\n",
      "24     neutral  At the first Grammy Awards, held on 4 May 1959...\n",
      "25    positive  @JennetteMcHevan I have studied all day but to...\n",
      "26    positive  Good morning Thursday. \"Life is fragile. We're...\n",
      "27    positive  #Twitition Mcfly come back to Argentina but th...\n",
      "28     neutral  #Broncos Peyton Manning named AFC Offensive Pl...\n",
      "29     neutral  @TooZany is bringing out Kendrick Lamar the 6t...\n",
      "...        ...                                                ...\n",
      "6906  positive  @TomFelton Hope you win tonight Tom!  Your US ...\n",
      "6907  positive  RT @AlexO_3 Monday Night Football be the move ...\n",
      "6908   neutral  Colts owner Jim Irsay will give $64,753 to vic...\n",
      "6909  positive  If I'm reading the Twitter Trend list correctl...\n",
      "6910  positive                           Colts game tonight! Yay!\n",
      "6911   neutral  Is this on tv again? \"@kugrlover: Most of Reds...\n",
      "6912  positive  What will have a better TV rating...#Cardinals...\n",
      "6913  positive  Yes. I'm ready for HS, college & pro. Bring it...\n",
      "6914  positive  Trying to leave, I'm only 10 minutes late (so ...\n",
      "6915  negative  I fail to see why the Rams are playing TWICE o...\n",
      "6916  negative  @Hopesolofans1 @hopesolo I hope my iPhone gets...\n",
      "6917   neutral           On the night Hank Williams came to town.\n",
      "6918  positive  RT @SmileLikeMiley: There won't be just a Part...\n",
      "6919  positive  Man was that Jets and Cowboys game awesome or ...\n",
      "6920  positive                   MNF tonight! Let's go Sexy Rexy!\n",
      "6921  negative  Lmao RT @HeatherNoel13: Curtis painter looks l...\n",
      "6922   neutral  Monday Night Football #TeamTexans all day & to...\n",
      "6923   neutral  @PierreGarcon85 come out and watch THOSE GUYS ...\n",
      "6924  negative  Hank Williams & whisky in an empty bar on a Fr...\n",
      "6925  positive  @kristiyamaguchi @markballas love that you 2 k...\n",
      "6926  positive  Huge thanks to those of you who came out to my...\n",
      "6927  negative  RT @Rach_RVX: #Londonriots is trending 3rd wor...\n",
      "6928  positive  Monday Night Football - Gary Neville did well ...\n",
      "6929  positive  @andrewsikora The Tigers know it's a big game ...\n",
      "6930  positive  New cast of DWTS tba at 8pm tonight!! So excit...\n",
      "6931  negative  @stoney16 @JeffMossDSR I'd recommend just turn...\n",
      "6932  positive  RT @MNFootNg It's monday and Monday Night Foot...\n",
      "6933  positive  All I know is the road for that Lomardi start ...\n",
      "6934   neutral  All Blue and White fam, we r meeting at Golden...\n",
      "6935  positive  @DariusButler28   Have a great game agaist Tam...\n",
      "\n",
      "[6936 rows x 2 columns]\n",
      "-----Data-------\n"
     ]
    }
   ],
   "source": [
    "#Read data from dataset\n",
    "#data = pd.read_csv(\"mbti_1.csv\") \n",
    "#shortdata=data.iloc[:,-1]\n",
    "arr=[]\n",
    "file = open(\"downloaded1.csv\",'rt')\n",
    "samples=csv.reader(file)\n",
    "c=0\n",
    "for i in samples:\n",
    "    c+=1\n",
    "    \n",
    "    if c==2:\n",
    "        x=i[1]\n",
    "        break\n",
    "\n",
    "for i in samples:\n",
    "    if i[1]!=x:\n",
    "        arr.append(i)\n",
    "\n",
    "\n",
    "df=pd.DataFrame(data=arr,columns=(\"types\",\"posts\"))\n",
    "print(len(df.columns))\n",
    "print(df)\n",
    "#shortdata=shortdata.head()\n",
    "#shortdata1=data.iloc[0:5,0]\n",
    "print('-----Data-------')\n",
    "#print(shortdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'neutral', 'positive']\n"
     ]
    }
   ],
   "source": [
    "def labelencode(df):\n",
    "    data=df['types']\n",
    "    values=np.array(data)\n",
    "    label=LabelEncoder()\n",
    "    intencode=label.fit_transform(values)\n",
    "    df['typeint']=intencode\n",
    "    print(list(label.inverse_transform([0,1,2])))\n",
    "    #df['typeint'].plot(kind='hist')\n",
    "    #k=np.arange(0,16)\n",
    "    #x=label.inverse_transform(k)   #can access encoded actual value using x\n",
    "    #print(values)\n",
    "    return df\n",
    "\n",
    "df=labelencode(df)\n",
    "#print(df)\n",
    "shortdata=df.iloc[:,1]\n",
    "#print(shortdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Removing stopwords------\n",
      "0       Iranian general says Israel's Iron Dome can't ...\n",
      "1       J Davlar 11th. Main rivals team Poland. Hopefu...\n",
      "2       Talking ACT's &amp;&amp; SAT's, deciding I wan...\n",
      "3       They may SuperBowl Dallas, Dallas ain't winnin...\n",
      "4       Im bringing monster load candy tomorrow, I hop...\n",
      "5       Apple software, retail chiefs overhaul: SAN FR...\n",
      "6       @oluoch @victor_otti @kunjand I watched it! Sr...\n",
      "7       #Livewire Nadal confirmed Mexican Open Februar...\n",
      "8       @MsSheLahY I didnt want pop up... yep chapel h...\n",
      "9       @Alyoup005 @addicted2haley hmmmm November odd ...\n",
      "10      #Iran US delisting MKO global terrorists list ...\n",
      "11      Good Morning Becky ! Thursday going Fantastic ...\n",
      "12      Expect light-moderate rains E. Visayas; Cebu, ...\n",
      "13      One ticket left @49ers game tomorrow! Don't mi...\n",
      "14      AFC away fans Saturday. All stuff 'she said no...\n",
      "15      Game 1 NLCS rematch NFC Championship game tomo...\n",
      "16      Never start working dreams goals tomorrow........\n",
      "17      @TheFFAddict I Vick Flacco, needed upgrade. Vi...\n",
      "18      Looks like Andy Android may little much fun ye...\n",
      "19      @APGPhoto oooh nice .. Tis tempting go lakes N...\n",
      "20      BLACK FRIDAY Huge Saving Aerial View City, Par...\n",
      "21      @MelmurMel @PBandJenelley_1 @vl_delp_ham_ Jene...\n",
      "22      Mohamed Morsi, Egypt's Muslim Brotherhood pres...\n",
      "23      C'mon Avila! You got tagged guy looks like kid...\n",
      "24      At first Grammy Awards, held 4 May 1959, Domen...\n",
      "25      @JennetteMcHevan I studied day tomorrow I'm go...\n",
      "26      Good morning Thursday. \"Life fragile. We're gu...\n",
      "27      #Twitition Mcfly come back Argentina time want...\n",
      "28      #Broncos Peyton Manning named AFC Offensive Pl...\n",
      "29      @TooZany bringing Kendrick Lamar 6th December!...\n",
      "                              ...                        \n",
      "6906    @TomFelton Hope win tonight Tom! Your US world...\n",
      "6907          RT @AlexO_3 Monday Night Football move too!\n",
      "6908    Colts owner Jim Irsay give $64,753 victims fun...\n",
      "6909    If I'm reading Twitter Trend list correctly, p...\n",
      "6910                             Colts game tonight! Yay!\n",
      "6911    Is tv again? \"@kugrlover: Most Redskins starte...\n",
      "6912    What better TV rating...#Cardinals v #Rockies ...\n",
      "6913    Yes. I'm ready HS, college & pro. Bring it! @b...\n",
      "6914    Trying leave, I'm 10 minutes late (so far) - s...\n",
      "6915    I fail see Rams playing TWICE MNF Fall-isn't e...\n",
      "6916    @Hopesolofans1 @hopesolo I hope iPhone gets se...\n",
      "6917                    On night Hank Williams came town.\n",
      "6918    RT @SmileLikeMiley: There Party USA tonight th...\n",
      "6919    Man Jets Cowboys game awesome what. Great ente...\n",
      "6920                     MNF tonight! Let's go Sexy Rexy!\n",
      "6921    Lmao RT @HeatherNoel13: Curtis painter looks l...\n",
      "6922    Monday Night Football #TeamTexans day & tomorr...\n",
      "6923    @PierreGarcon85 come watch THOSE GUYS softball...\n",
      "6924    Hank Williams & whisky empty bar Friday. Reall...\n",
      "6925    @kristiyamaguchi @markballas love 2 keep touch...\n",
      "6926    Huge thanks came photography workshops today T...\n",
      "6927    RT @Rach_RVX: #Londonriots trending 3rd worldw...\n",
      "6928    Monday Night Football - Gary Neville well even...\n",
      "6929    @andrewsikora The Tigers know big game well: r...\n",
      "6930    New cast DWTS tba 8pm tonight!! So excited :) ...\n",
      "6931    @stoney16 @JeffMossDSR I'd recommend turning w...\n",
      "6932    RT @MNFootNg It's monday Monday Night Football...\n",
      "6933    All I know road Lomardi start TONIGHT!!!! We s...\n",
      "6934    All Blue White fam, r meeting Golden Corral di...\n",
      "6935    @DariusButler28 Have great game agaist Tampa B...\n",
      "Name: posts, Length: 6936, dtype: object\n",
      "-------Stemming--------\n",
      "0       iranian gener say israel' iron dome can't deal...\n",
      "1       J davlar 11th. main rival team poland. hope ma...\n",
      "2       talk act' &amp;&amp; sat's, decid I want go co...\n",
      "3       they may superbowl dallas, dalla ain't win sup...\n",
      "4       Im bring monster load candi tomorrow, I hope g...\n",
      "5       appl software, retail chief overhaul: san fran...\n",
      "6       @oluoch @victor_otti @kunjand I watch it! srid...\n",
      "7       #livewir nadal confirm mexican open february: ...\n",
      "8       @msshelahi I didnt want pop up... yep chapel h...\n",
      "9       @alyoup005 @addicted2haley hmmmm novemb odd re...\n",
      "10      #iran US delist mko global terrorist list line...\n",
      "11      good morn becki ! thursday go fantast ! @swede...\n",
      "12      expect light-moder rain E. visayas; cebu, boho...\n",
      "13      one ticket left @49er game tomorrow! don't mis...\n",
      "14      afc away fan saturday. all stuff 'she said no'...\n",
      "15      game 1 nlc rematch nfc championship game tomor...\n",
      "16      never start work dream goal tomorrow......tomo...\n",
      "17      @theffaddict I vick flacco, need upgrade. vick...\n",
      "18      look like andi android may littl much fun yest...\n",
      "19      @apgphoto oooh nice .. ti tempt go lake nikon ...\n",
      "20      black friday huge save aerial view city, pari ...\n",
      "21      @melmurmel @pbandjenelley_1 @vl_delp_ham_ jene...\n",
      "22      moham morsi, egypt' muslim brotherhood preside...\n",
      "23      c'mon avila! you got tag guy look like kid bil...\n",
      "24      At first grammi awards, held 4 may 1959, domen...\n",
      "25      @jennettemchevan I studi day tomorrow i'm go f...\n",
      "26      good morn thursday. \"life fragile. we'r guaran...\n",
      "27      #twitit mcfli come back argentina time want co...\n",
      "28      #bronco peyton man name afc offens player mont...\n",
      "29      @toozani bring kendrick lamar 6th december!?! ...\n",
      "                              ...                        \n",
      "6906    @tomfelton hope win tonight tom! your US world...\n",
      "6907           RT @alexo_3 monday night footbal move too!\n",
      "6908    colt owner jim irsay give $64,753 victim fund ...\n",
      "6909    If i'm read twitter trend list correctly, peop...\n",
      "6910                              colt game tonight! yay!\n",
      "6911    Is tv again? \"@kugrlover: most redskin starter...\n",
      "6912    what better TV rating...#cardin v #rocki tonig...\n",
      "6913    yes. i'm readi hs, colleg & pro. bring it! @bl...\n",
      "6914    tri leave, i'm 10 minut late (so far) - still ...\n",
      "6915    I fail see ram play twice mnf fall-isn't enoug...\n",
      "6916    @hopesolofans1 @hopesolo I hope iphon get serv...\n",
      "6917                     On night hank william came town.\n",
      "6918    RT @smilelikemiley: there parti usa tonight th...\n",
      "6919    man jet cowboy game awesom what. great enterta...\n",
      "6920                      mnf tonight! let' go sexi rexy!\n",
      "6921    lmao RT @heathernoel13: curti painter look lik...\n",
      "6922    monday night footbal #teamtexan day & tomorrow...\n",
      "6923    @pierregarcon85 come watch those guy softbal n...\n",
      "6924    hank william & whiski empti bar friday. really...\n",
      "6925    @kristiyamaguchi @markballa love 2 keep touch ...\n",
      "6926    huge thank came photographi workshop today ter...\n",
      "6927    RT @rach_rvx: #londonriot trend 3rd worldwid ....\n",
      "6928    monday night footbal - gari nevil well even ti...\n",
      "6929    @andrewsikora the tiger know big game well: re...\n",
      "6930    new cast dwt tba 8pm tonight!! So excit :) the...\n",
      "6931    @stoney16 @jeffmossdsr i'd recommend turn wait...\n",
      "6932    RT @mnfootng it' monday monday night footbal m...\n",
      "6933    all I know road lomardi start tonight!!!! We s...\n",
      "6934    all blue white fam, r meet golden corral dinne...\n",
      "6935    @dariusbutler28 have great game agaist tampa b...\n",
      "Name: posts, Length: 6936, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#removing stopwords \n",
    "from nltk.corpus import stopwords\n",
    "stop=stopwords.words(\"english\")\n",
    "print('------Removing stopwords------')\n",
    "shortdata=shortdata.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "#shortdata=shortdata.apply(lambda x: ' '.join([word for word in x.split() if word!='i' or word!='I']))\n",
    "print(shortdata)\n",
    "#stemming of words\n",
    "ps = PorterStemmer()\n",
    "print('-------Stemming--------')\n",
    "shortdata = shortdata.apply(lambda x: ' '.join([ps.stem(word) for word in x.split() ]))\n",
    "print(shortdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Lemmatization--------\n",
      "0       iranian gener say iron dome deal missil talk l...\n",
      "1       J davlar main rival team hope make success end...\n",
      "2       talk decid I want go appli colleg everyth coll...\n",
      "3            they may superbowl dalla win not quarterback\n",
      "4           Im bring monster load candi I hope get squich\n",
      "5       appl retail chief san francisco appl inc ceo t...\n",
      "6                           I watch U rememb sun morn nta\n",
      "7        nadal confirm mexican open rafael nadal set play\n",
      "8       I didnt want pop yep chapel hill next wednesda...\n",
      "9       hmmmm novemb odd releas date true becom big en...\n",
      "10      US delist mko global terrorist list line iran ...\n",
      "11                    good morn becki thursday go fantast\n",
      "12      expect rain samar leyt chanc rain expect fair ...\n",
      "13      one ticket leave game miss rematch nfc champio...\n",
      "14              afc away fan all stuff say when turn back\n",
      "15      game nlc rematch nfc championship game gonna c...\n",
      "16       never start work dream goal never mean anyth act\n",
      "17          I vick need vick may get jen back I think win\n",
      "18              look like andi android may littl much fun\n",
      "19           oooh nice ti tempt go lake nikon hmmmm I may\n",
      "20      black friday huge save aerial view pari la la ...\n",
      "21                               jenel say alon say weird\n",
      "22      moham muslim brotherhood instruct suprem counc...\n",
      "23      you get tag guy look like kid bill murray rese...\n",
      "24      At first grammi hold may domenico modugno beat...\n",
      "25              I studi day tomorrow go omg jennett gonna\n",
      "26      good morn guarante tomorrow give everyth tim cook\n",
      "27       mcfli come back argentina time want come mar del\n",
      "28       peyton man name afc offens player second tom tie\n",
      "29                        bring kendrick lamar get ticket\n",
      "                              ...                        \n",
      "6906          hope win tonight your US worldwid fan cheer\n",
      "6907                         RT monday night footbal move\n",
      "6908    colt owner jim irsay give victim fund state fa...\n",
      "6909    If read twitter trend list peopl realli happi ...\n",
      "6910                                            colt game\n",
      "6911    Is tv most redskin starter sit tonight vs tamp...\n",
      "6912    what better TV v tonight mnf reg season hardba...\n",
      "6913    readi colleg bring make monday We come home yo...\n",
      "6914    tri minut late still need dash ladi wait hear dwt\n",
      "6915      I fail see ram play twice mnf div game isnt til\n",
      "6916    I hope iphon get servic tonit find dwt caus I ...\n",
      "6917                           On night hank william come\n",
      "6918    RT there parti usa tonight parti worldwid mile...\n",
      "6919    man jet cowboy game awesom great entertain tha...\n",
      "6920                                          mnf go sexi\n",
      "6921    lmao RT curti painter look like kind guy would...\n",
      "6922                             monday night footbal day\n",
      "6923    come watch those guy softbal next saturday aug...\n",
      "6924    hank william whiski empti bar guy cute bartend...\n",
      "6925    love keep touch one favorit dwt coupl reason I...\n",
      "6926     huge thank come photographi workshop today terra\n",
      "6927     RT trend worldwid thi not someth proud unit sort\n",
      "6928    monday night footbal gari nevil well even time...\n",
      "6929    the tiger know big game rest martinez alburque...\n",
      "6930    new cast dwt tba So excit the meet tonight bet...\n",
      "6931                          recommend turn wait verland\n",
      "6932               RT monday monday night footbal RT love\n",
      "6933    all I know road lomardi start We set record mn...\n",
      "6934    all blue white r meet golden corral dinner ton...\n",
      "6935                     have great game agaist tampa bay\n",
      "Name: posts, Length: 6936, dtype: object\n",
      "--------Removing punctuations--------\n",
      "0       iranian gener say iron dome deal missil talk l...\n",
      "1       J davlar main rival team hope make success end...\n",
      "2       talk decid I want go appli colleg everyth coll...\n",
      "3            they may superbowl dalla win not quarterback\n",
      "4           Im bring monster load candi I hope get squich\n",
      "5       appl retail chief san francisco appl inc ceo t...\n",
      "6                           I watch U rememb sun morn nta\n",
      "7        nadal confirm mexican open rafael nadal set play\n",
      "8       I didnt want pop yep chapel hill next wednesda...\n",
      "9       hmmmm novemb odd releas date true becom big en...\n",
      "10      US delist mko global terrorist list line iran ...\n",
      "11                    good morn becki thursday go fantast\n",
      "12      expect rain samar leyt chanc rain expect fair ...\n",
      "13      one ticket leave game miss rematch nfc champio...\n",
      "14              afc away fan all stuff say when turn back\n",
      "15      game nlc rematch nfc championship game gonna c...\n",
      "16       never start work dream goal never mean anyth act\n",
      "17          I vick need vick may get jen back I think win\n",
      "18              look like andi android may littl much fun\n",
      "19           oooh nice ti tempt go lake nikon hmmmm I may\n",
      "20      black friday huge save aerial view pari la la ...\n",
      "21                               jenel say alon say weird\n",
      "22      moham muslim brotherhood instruct suprem counc...\n",
      "23      you get tag guy look like kid bill murray rese...\n",
      "24      At first grammi hold may domenico modugno beat...\n",
      "25              I studi day tomorrow go omg jennett gonna\n",
      "26      good morn guarante tomorrow give everyth tim cook\n",
      "27       mcfli come back argentina time want come mar del\n",
      "28       peyton man name afc offens player second tom tie\n",
      "29                        bring kendrick lamar get ticket\n",
      "                              ...                        \n",
      "6906          hope win tonight your US worldwid fan cheer\n",
      "6907                         RT monday night footbal move\n",
      "6908    colt owner jim irsay give victim fund state fa...\n",
      "6909    If read twitter trend list peopl realli happi ...\n",
      "6910                                            colt game\n",
      "6911    Is tv most redskin starter sit tonight vs tamp...\n",
      "6912    what better TV v tonight mnf reg season hardba...\n",
      "6913    readi colleg bring make monday We come home yo...\n",
      "6914    tri minut late still need dash ladi wait hear dwt\n",
      "6915      I fail see ram play twice mnf div game isnt til\n",
      "6916    I hope iphon get servic tonit find dwt caus I ...\n",
      "6917                           On night hank william come\n",
      "6918    RT there parti usa tonight parti worldwid mile...\n",
      "6919    man jet cowboy game awesom great entertain tha...\n",
      "6920                                          mnf go sexi\n",
      "6921    lmao RT curti painter look like kind guy would...\n",
      "6922                             monday night footbal day\n",
      "6923    come watch those guy softbal next saturday aug...\n",
      "6924    hank william whiski empti bar guy cute bartend...\n",
      "6925    love keep touch one favorit dwt coupl reason I...\n",
      "6926     huge thank come photographi workshop today terra\n",
      "6927     RT trend worldwid thi not someth proud unit sort\n",
      "6928    monday night footbal gari nevil well even time...\n",
      "6929    the tiger know big game rest martinez alburque...\n",
      "6930    new cast dwt tba So excit the meet tonight bet...\n",
      "6931                          recommend turn wait verland\n",
      "6932               RT monday monday night footbal RT love\n",
      "6933    all I know road lomardi start We set record mn...\n",
      "6934    all blue white r meet golden corral dinner ton...\n",
      "6935                     have great game agaist tampa bay\n",
      "Name: posts, Length: 6936, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#removing non-alphabets\n",
    "shortdata=shortdata.apply(lambda x: ' '.join([word for word in x.split() if word.isalpha()]))\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lmtzr = WordNetLemmatizer()\n",
    "#print(shortdata)\n",
    "print('-------Lemmatization--------')\n",
    "shortdata = shortdata.apply(lambda x: ' '.join([lmtzr.lemmatize(word,'v') for word in x.split() ]))\n",
    "print(shortdata)\n",
    "\n",
    "print('--------Removing punctuations--------')\n",
    "def clear_punctuation(s):\n",
    "\timport string\n",
    "\t#print(\"\\n\")\n",
    "\tclear_string = \"\"\n",
    "\tfor symbol in s:\n",
    "\t\tif symbol not in string.punctuation:\n",
    "\t\t\tclear_string += symbol\n",
    "\treturn clear_string\n",
    "\n",
    "shortdata = shortdata.apply(lambda x: ''.join(clear_punctuation(x))  )\n",
    "print(shortdata)\n",
    "#for line in shortdata:\n",
    "#\tprint(line)\n",
    "#\tprint('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_all_entities(text):\n",
    "\timport string\n",
    "\tentity_prefixes = ['@']\n",
    "\tfor separator in  string.punctuation:\n",
    "\t\tif separator not in entity_prefixes :\n",
    "\t\t\ttext = text.replace(separator,' ')\n",
    "\twords = []\n",
    "\tfor word in text.split():\n",
    "\t\tword = word.strip()\n",
    "\t\tif word:\n",
    "\t\t\tif word[0] not in entity_prefixes:\n",
    "\t\t\t\twords.append(word)\n",
    "\treturn ' '.join(words)\n",
    "\n",
    "shortdata = shortdata.apply(lambda x: ''.join(strip_all_entities(x))  ) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----PREPROCESSED_DATA------\n",
      "         types                                              posts  typeint\n",
      "0     negative  iranian gener say iron dome deal missil talk l...        0\n",
      "1     positive  J davlar main rival team hope make success end...        2\n",
      "2     negative  talk decid I want go appli colleg everyth coll...        0\n",
      "3     negative       they may superbowl dalla win not quarterback        0\n",
      "4      neutral      Im bring monster load candi I hope get squich        1\n",
      "5      neutral  appl retail chief san francisco appl inc ceo t...        1\n",
      "6     positive                      I watch U rememb sun morn nta        2\n",
      "7      neutral   nadal confirm mexican open rafael nadal set play        1\n",
      "8     positive  I didnt want pop yep chapel hill next wednesda...        2\n",
      "9      neutral  hmmmm novemb odd releas date true becom big en...        1\n",
      "10     neutral  US delist mko global terrorist list line iran ...        1\n",
      "11    positive                good morn becki thursday go fantast        2\n",
      "12     neutral  expect rain samar leyt chanc rain expect fair ...        1\n",
      "13    positive  one ticket leave game miss rematch nfc champio...        2\n",
      "14    negative          afc away fan all stuff say when turn back        0\n",
      "15     neutral  game nlc rematch nfc championship game gonna c...        1\n",
      "16    positive   never start work dream goal never mean anyth act        2\n",
      "17    positive      I vick need vick may get jen back I think win        2\n",
      "18    positive          look like andi android may littl much fun        2\n",
      "19    positive       oooh nice ti tempt go lake nikon hmmmm I may        2\n",
      "20     neutral  black friday huge save aerial view pari la la ...        1\n",
      "21    negative                           jenel say alon say weird        0\n",
      "22     neutral  moham muslim brotherhood instruct suprem counc...        1\n",
      "23     neutral  you get tag guy look like kid bill murray rese...        1\n",
      "24     neutral  At first grammi hold may domenico modugno beat...        1\n",
      "25    positive          I studi day tomorrow go omg jennett gonna        2\n",
      "26    positive  good morn guarante tomorrow give everyth tim cook        2\n",
      "27    positive   mcfli come back argentina time want come mar del        2\n",
      "28     neutral   peyton man name afc offens player second tom tie        1\n",
      "29     neutral                    bring kendrick lamar get ticket        1\n",
      "...        ...                                                ...      ...\n",
      "6906  positive        hope win tonight your US worldwid fan cheer        2\n",
      "6907  positive                       RT monday night footbal move        2\n",
      "6908   neutral  colt owner jim irsay give victim fund state fa...        1\n",
      "6909  positive  If read twitter trend list peopl realli happi ...        2\n",
      "6910  positive                                          colt game        2\n",
      "6911   neutral  Is tv most redskin starter sit tonight vs tamp...        1\n",
      "6912  positive  what better TV v tonight mnf reg season hardba...        2\n",
      "6913  positive  readi colleg bring make monday We come home yo...        2\n",
      "6914  positive  tri minut late still need dash ladi wait hear dwt        2\n",
      "6915  negative    I fail see ram play twice mnf div game isnt til        0\n",
      "6916  negative  I hope iphon get servic tonit find dwt caus I ...        0\n",
      "6917   neutral                         On night hank william come        1\n",
      "6918  positive  RT there parti usa tonight parti worldwid mile...        2\n",
      "6919  positive  man jet cowboy game awesom great entertain tha...        2\n",
      "6920  positive                                        mnf go sexi        2\n",
      "6921  negative  lmao RT curti painter look like kind guy would...        0\n",
      "6922   neutral                           monday night footbal day        1\n",
      "6923   neutral  come watch those guy softbal next saturday aug...        1\n",
      "6924  negative  hank william whiski empti bar guy cute bartend...        0\n",
      "6925  positive  love keep touch one favorit dwt coupl reason I...        2\n",
      "6926  positive   huge thank come photographi workshop today terra        2\n",
      "6927  negative   RT trend worldwid thi not someth proud unit sort        0\n",
      "6928  positive  monday night footbal gari nevil well even time...        2\n",
      "6929  positive  the tiger know big game rest martinez alburque...        2\n",
      "6930  positive  new cast dwt tba So excit the meet tonight bet...        2\n",
      "6931  negative                        recommend turn wait verland        0\n",
      "6932  positive             RT monday monday night footbal RT love        2\n",
      "6933  positive  all I know road lomardi start We set record mn...        2\n",
      "6934   neutral  all blue white r meet golden corral dinner ton...        1\n",
      "6935  positive                   have great game agaist tampa bay        2\n",
      "\n",
      "[6936 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'for column in dataset.columns:\\n    if dataset[column].dtype == type(object):\\n        le = LabelEncoder()\\n        dataset[column] = le.fit_transform(dataset[column])'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "arr=[]\n",
    "print(\"-----PREPROCESSED_DATA------\")\n",
    "count=0\n",
    "for line in shortdata:\n",
    "    df.iloc[i,1]=line\n",
    "    i=i+1\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "'''for column in dataset.columns:\n",
    "    if dataset[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        dataset[column] = le.fit_transform(dataset[column])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6936\n",
      "6936\n"
     ]
    }
   ],
   "source": [
    "proc_data=np.array(df['posts'])\n",
    "label=np.array(df['typeint'])\n",
    "print(len(proc_data))\n",
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(proc_data, label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thank come mardi gra juli fullerton downtown plaza last all proce'\n",
      " 'go tuesday hous blue see rocki'\n",
      " 'miss day rel would gather uncl hous celebr chin new year I guess happen agn'\n",
      " ... 'look like guy fun x'\n",
      " 'yall nigga must differ version taylor track alreadi wanna turn shit'\n",
      " 'hicksvil tiger final power class resum normal']\n"
     ]
    }
   ],
   "source": [
    "print(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import keras\n",
    "import keras.preprocessing.text as kpt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# only work with the 3000 most popular words found in our dataset\n",
    "max_words = 3000\n",
    "\n",
    "# create a new Tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "# feed our tweets to the Tokenizer\n",
    "tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "# Tokenizers come with a convenient list of words and IDs\n",
    "dictionary = tokenizer.word_index\n",
    "# Let's save this out so we can use it later\n",
    "with open('dictionary.json', 'w') as dictionary_file:\n",
    "    json.dump(dictionary, dictionary_file)\n",
    "\n",
    "\n",
    "def convert_text_to_index_array(text):\n",
    "    # one really important thing that `text_to_word_sequence` does\n",
    "    # is make all texts the same length -- in this case, the length\n",
    "    # of the longest text in the set.\n",
    "    return [dictionary[word] for word in kpt.text_to_word_sequence(text)]\n",
    "\n",
    "allWordIndices = []\n",
    "# for each tweet, change each token to its ID in the Tokenizer's word_index\n",
    "for text in train_x:\n",
    "    wordIndices = convert_text_to_index_array(text)\n",
    "    allWordIndices.append(wordIndices)\n",
    "\n",
    "# now we have a list of all tweets converted to index arrays.\n",
    "# cast as an array for future usage.\n",
    "allWordIndices = np.asarray(allWordIndices)\n",
    "\n",
    "# create one-hot matrices out of the indexed tweets\n",
    "train_x = tokenizer.sequences_to_matrix(allWordIndices, mode='binary')\n",
    "# treat the labels as categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = keras.utils.to_categorical(train_y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_shape=(max_words,), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "sgd=keras.optimizers.SGD(lr=0.5, momentum=0.0, decay=0.0, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "  optimizer=sgd,\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4993 samples, validate on 555 samples\n",
      "Epoch 1/5\n",
      "4993/4993 [==============================] - 2s 367us/step - loss: 0.9232 - acc: 0.5668 - val_loss: 1.5960 - val_acc: 0.3658\n",
      "Epoch 2/5\n",
      "4993/4993 [==============================] - 2s 335us/step - loss: 0.7783 - acc: 0.6553 - val_loss: 1.1922 - val_acc: 0.5423\n",
      "Epoch 3/5\n",
      "4993/4993 [==============================] - 2s 326us/step - loss: 0.6352 - acc: 0.7342 - val_loss: 2.4766 - val_acc: 0.1964\n",
      "Epoch 4/5\n",
      "4993/4993 [==============================] - 2s 336us/step - loss: 0.5663 - acc: 0.7683 - val_loss: 2.6976 - val_acc: 0.2036\n",
      "Epoch 5/5\n",
      "4993/4993 [==============================] - 2s 324us/step - loss: 0.4562 - acc: 0.8266 - val_loss: 1.2075 - val_acc: 0.6288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f19847c0b38>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y,\n",
    "  batch_size=32,\n",
    "  epochs=5,\n",
    "  verbose=1,\n",
    "  validation_split=0.1,\n",
    "  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open('model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.preprocessing.text as kpt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# we're still going to use a Tokenizer here, but we don't need to fit it\n",
    "tokenizer = Tokenizer(num_words=3000)\n",
    "# for human-friendly printing\n",
    "labels = ['negative','neutral','positive']\n",
    "\n",
    "# read in our saved dictionary\n",
    "with open('dictionary.json', 'r') as dictionary_file:\n",
    "    dictionary = json.load(dictionary_file)\n",
    "\n",
    "# this utility makes sure that all the words in your input\n",
    "# are registered in the dictionary\n",
    "# before trying to turn them into a matrix.\n",
    "def convert_text_to_index_array(text):\n",
    "    words = kpt.text_to_word_sequence(text)\n",
    "    wordIndices = []\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            wordIndices.append(dictionary[word])\n",
    "        else:\n",
    "            print(\"'%s' not in training corpus; ignoring.\" %(word))\n",
    "    return wordIndices\n",
    "\n",
    "# read in your saved model structure\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "# and create a model from that\n",
    "model = model_from_json(loaded_model_json)\n",
    "# and weight your nodes with your saved values\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "# okay here's the interactive part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'are' not in training corpus; ignoring.\n",
      "neutral sentiment; 56.164402% confidence\n"
     ]
    }
   ],
   "source": [
    "eval=\"hello how are you?\"\n",
    "testArr = convert_text_to_index_array(eval)\n",
    "inp = tokenizer.sequences_to_matrix([testArr], mode='binary')\n",
    "# predict which bucket your input belongs in\n",
    "pred = model.predict(inp)\n",
    "# and print it for the humons\n",
    "print(\"%s sentiment; %f%% confidence\" % (labels[np.argmax(pred)], pred[0][np.argmax(pred)] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['If end I commend emot gari carter memori show februari'\n",
      " 'need break come kickbal tournament tomorrow behind'\n",
      " 'more inform new comm de garcon fragranc launch church next wednesday'\n",
      " ... 'go clutch billiard backroom KY dec'\n",
      " 'tonight colt fan go say man john beck'\n",
      " 'great show get get catch david letterman']\n"
     ]
    }
   ],
   "source": [
    "print(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'commend' not in training corpus; ignoring.\n",
      "'garcon' not in training corpus; ignoring.\n",
      "'fragranc' not in training corpus; ignoring.\n",
      "'approach' not in training corpus; ignoring.\n",
      "'bashaara' not in training corpus; ignoring.\n",
      "'grave' not in training corpus; ignoring.\n",
      "'chainz' not in training corpus; ignoring.\n",
      "'callum' not in training corpus; ignoring.\n",
      "'mtv' not in training corpus; ignoring.\n",
      "'johnn' not in training corpus; ignoring.\n",
      "'alumni' not in training corpus; ignoring.\n",
      "'bartlett' not in training corpus; ignoring.\n",
      "'trio' not in training corpus; ignoring.\n",
      "'bass' not in training corpus; ignoring.\n",
      "'cenla' not in training corpus; ignoring.\n",
      "'colfax' not in training corpus; ignoring.\n",
      "'brandenberg' not in training corpus; ignoring.\n",
      "'divin' not in training corpus; ignoring.\n",
      "'rowdi' not in training corpus; ignoring.\n",
      "'tcaformiley' not in training corpus; ignoring.\n",
      "'veilrt' not in training corpus; ignoring.\n",
      "'irt' not in training corpus; ignoring.\n",
      "'lagu' not in training corpus; ignoring.\n",
      "'demen' not in training corpus; ignoring.\n",
      "'hbu' not in training corpus; ignoring.\n",
      "'tremend' not in training corpus; ignoring.\n",
      "'kedzi' not in training corpus; ignoring.\n",
      "'ambassador' not in training corpus; ignoring.\n",
      "'mma' not in training corpus; ignoring.\n",
      "'bcwmh' not in training corpus; ignoring.\n",
      "'hire' not in training corpus; ignoring.\n",
      "'restraint' not in training corpus; ignoring.\n",
      "'brawl' not in training corpus; ignoring.\n",
      "'cpr' not in training corpus; ignoring.\n",
      "'cornwal' not in training corpus; ignoring.\n",
      "'padstow' not in training corpus; ignoring.\n",
      "'chip' not in training corpus; ignoring.\n",
      "'baggi' not in training corpus; ignoring.\n",
      "'autodraft' not in training corpus; ignoring.\n",
      "'gentli' not in training corpus; ignoring.\n",
      "'recruit' not in training corpus; ignoring.\n",
      "'aphex' not in training corpus; ignoring.\n",
      "'inter' not in training corpus; ignoring.\n",
      "'inter' not in training corpus; ignoring.\n",
      "'bake' not in training corpus; ignoring.\n",
      "'narita' not in training corpus; ignoring.\n",
      "'tenbi' not in training corpus; ignoring.\n",
      "'worship' not in training corpus; ignoring.\n",
      "'gmwa' not in training corpus; ignoring.\n",
      "'marriott' not in training corpus; ignoring.\n",
      "'snowi' not in training corpus; ignoring.\n",
      "'intens' not in training corpus; ignoring.\n",
      "'rossomando' not in training corpus; ignoring.\n",
      "'durham' not in training corpus; ignoring.\n",
      "'irsay' not in training corpus; ignoring.\n",
      "'brah' not in training corpus; ignoring.\n",
      "'regal' not in training corpus; ignoring.\n",
      "'skank' not in training corpus; ignoring.\n",
      "'nlc' not in training corpus; ignoring.\n",
      "'cuuuuhraaaaaaaazeeee' not in training corpus; ignoring.\n",
      "'maggett' not in training corpus; ignoring.\n",
      "'wtf' not in training corpus; ignoring.\n",
      "'milwauke' not in training corpus; ignoring.\n",
      "'sejesong' not in training corpus; ignoring.\n",
      "'imbizo' not in training corpus; ignoring.\n",
      "'midrand' not in training corpus; ignoring.\n",
      "'ivori' not in training corpus; ignoring.\n",
      "'ext' not in training corpus; ignoring.\n",
      "'mvpc' not in training corpus; ignoring.\n",
      "'tjo' not in training corpus; ignoring.\n",
      "'rebat' not in training corpus; ignoring.\n",
      "'resist' not in training corpus; ignoring.\n",
      "'solv' not in training corpus; ignoring.\n",
      "'audi' not in training corpus; ignoring.\n",
      "'bmw' not in training corpus; ignoring.\n",
      "'cian' not in training corpus; ignoring.\n",
      "'mybe' not in training corpus; ignoring.\n",
      "'bisaa' not in training corpus; ignoring.\n",
      "'alumni' not in training corpus; ignoring.\n",
      "'dian' not in training corpus; ignoring.\n",
      "'evangelist' not in training corpus; ignoring.\n",
      "'directli' not in training corpus; ignoring.\n",
      "'creepi' not in training corpus; ignoring.\n",
      "'ayy' not in training corpus; ignoring.\n",
      "'bib' not in training corpus; ignoring.\n",
      "'cult' not in training corpus; ignoring.\n",
      "'miner' not in training corpus; ignoring.\n",
      "'foundri' not in training corpus; ignoring.\n",
      "'wolfpack' not in training corpus; ignoring.\n",
      "'trent' not in training corpus; ignoring.\n",
      "'reo' not in training corpus; ignoring.\n",
      "'bon' not in training corpus; ignoring.\n",
      "'jovi' not in training corpus; ignoring.\n",
      "'lure' not in training corpus; ignoring.\n",
      "'tediou' not in training corpus; ignoring.\n",
      "'bogosian' not in training corpus; ignoring.\n",
      "'winnipeg' not in training corpus; ignoring.\n",
      "'thiiissss' not in training corpus; ignoring.\n",
      "'mofo' not in training corpus; ignoring.\n",
      "'panic' not in training corpus; ignoring.\n",
      "'pushin' not in training corpus; ignoring.\n",
      "'rch' not in training corpus; ignoring.\n",
      "'faggot' not in training corpus; ignoring.\n",
      "'mitten' not in training corpus; ignoring.\n",
      "'affection' not in training corpus; ignoring.\n",
      "'worship' not in training corpus; ignoring.\n",
      "'freebi' not in training corpus; ignoring.\n",
      "'prototyp' not in training corpus; ignoring.\n",
      "'quadrotor' not in training corpus; ignoring.\n",
      "'imposs' not in training corpus; ignoring.\n",
      "'animalsens' not in training corpus; ignoring.\n",
      "'cfc' not in training corpus; ignoring.\n",
      "'harm' not in training corpus; ignoring.\n",
      "'retain' not in training corpus; ignoring.\n",
      "'wbc' not in training corpus; ignoring.\n",
      "'heavyweight' not in training corpus; ignoring.\n",
      "'makin' not in training corpus; ignoring.\n",
      "'heebi' not in training corpus; ignoring.\n",
      "'jeebi' not in training corpus; ignoring.\n",
      "'ibb' not in training corpus; ignoring.\n",
      "'topeka' not in training corpus; ignoring.\n",
      "'dsu' not in training corpus; ignoring.\n",
      "'dsu' not in training corpus; ignoring.\n",
      "'trafford' not in training corpus; ignoring.\n",
      "'liner' not in training corpus; ignoring.\n",
      "'typo' not in training corpus; ignoring.\n",
      "'hernia' not in training corpus; ignoring.\n",
      "'crab' not in training corpus; ignoring.\n",
      "'linen' not in training corpus; ignoring.\n",
      "'mmg' not in training corpus; ignoring.\n",
      "'metlif' not in training corpus; ignoring.\n",
      "'blimp' not in training corpus; ignoring.\n",
      "'ms' not in training corpus; ignoring.\n",
      "'marek' not in training corpus; ignoring.\n",
      "'flowerpot' not in training corpus; ignoring.\n",
      "'fond' not in training corpus; ignoring.\n",
      "'dann' not in training corpus; ignoring.\n",
      "'whilst' not in training corpus; ignoring.\n",
      "'bowler' not in training corpus; ignoring.\n",
      "'extrem' not in training corpus; ignoring.\n",
      "'raina' not in training corpus; ignoring.\n",
      "'rayudu' not in training corpus; ignoring.\n",
      "'yeaa' not in training corpus; ignoring.\n",
      "'whisper' not in training corpus; ignoring.\n",
      "'monsoon' not in training corpus; ignoring.\n",
      "'midtown' not in training corpus; ignoring.\n",
      "'virgin' not in training corpus; ignoring.\n",
      "'liberalis' not in training corpus; ignoring.\n",
      "'liberalis' not in training corpus; ignoring.\n",
      "'surrey' not in training corpus; ignoring.\n",
      "'tvshow' not in training corpus; ignoring.\n",
      "'distress' not in training corpus; ignoring.\n",
      "'properti' not in training corpus; ignoring.\n",
      "'declin' not in training corpus; ignoring.\n",
      "'arlington' not in training corpus; ignoring.\n",
      "'nephew' not in training corpus; ignoring.\n",
      "'freight' not in training corpus; ignoring.\n",
      "'mop' not in training corpus; ignoring.\n",
      "'broom' not in training corpus; ignoring.\n",
      "'nth' not in training corpus; ignoring.\n",
      "'hectic' not in training corpus; ignoring.\n",
      "'ifeat' not in training corpus; ignoring.\n",
      "'harland' not in training corpus; ignoring.\n",
      "'sander' not in training corpus; ignoring.\n",
      "'mere' not in training corpus; ignoring.\n",
      "'swim' not in training corpus; ignoring.\n",
      "'cmag' not in training corpus; ignoring.\n",
      "'baag' not in training corpus; ignoring.\n",
      "'cmag' not in training corpus; ignoring.\n",
      "'currenc' not in training corpus; ignoring.\n",
      "'lololololololol' not in training corpus; ignoring.\n",
      "'strattonfaxon' not in training corpus; ignoring.\n",
      "'soltek' not in training corpus; ignoring.\n",
      "'daffadam' not in training corpus; ignoring.\n",
      "'medlam' not in training corpus; ignoring.\n",
      "'samar' not in training corpus; ignoring.\n",
      "'leyt' not in training corpus; ignoring.\n",
      "'woodchick' not in training corpus; ignoring.\n",
      "'malkin' not in training corpus; ignoring.\n",
      "'quotepenguin' not in training corpus; ignoring.\n",
      "'evgeni' not in training corpus; ignoring.\n",
      "'malkin' not in training corpus; ignoring.\n",
      "'tepco' not in training corpus; ignoring.\n",
      "'anaheim' not in training corpus; ignoring.\n",
      "'glu' not in training corpus; ignoring.\n",
      "'inq' not in training corpus; ignoring.\n",
      "'finest' not in training corpus; ignoring.\n",
      "'kg' not in training corpus; ignoring.\n",
      "'likeabl' not in training corpus; ignoring.\n",
      "'klasnic' not in training corpus; ignoring.\n",
      "'coup' not in training corpus; ignoring.\n",
      "'freebi' not in training corpus; ignoring.\n",
      "'limelight' not in training corpus; ignoring.\n",
      "'niner' not in training corpus; ignoring.\n",
      "'divin' not in training corpus; ignoring.\n",
      "'insan' not in training corpus; ignoring.\n",
      "'portray' not in training corpus; ignoring.\n",
      "'casey' not in training corpus; ignoring.\n",
      "'disciplin' not in training corpus; ignoring.\n",
      "'cakap' not in training corpus; ignoring.\n",
      "'fourteen' not in training corpus; ignoring.\n",
      "'intens' not in training corpus; ignoring.\n",
      "'hayley' not in training corpus; ignoring.\n",
      "'manciti' not in training corpus; ignoring.\n",
      "'aguero' not in training corpus; ignoring.\n",
      "'dzeko' not in training corpus; ignoring.\n",
      "'chicagoriff' not in training corpus; ignoring.\n",
      "'cult' not in training corpus; ignoring.\n",
      "'touchdown' not in training corpus; ignoring.\n",
      "'naw' not in training corpus; ignoring.\n",
      "'piper' not in training corpus; ignoring.\n",
      "'thorton' not in training corpus; ignoring.\n",
      "'iacc' not in training corpus; ignoring.\n",
      "'solidar' not in training corpus; ignoring.\n",
      "'magnific' not in training corpus; ignoring.\n",
      "'scallop' not in training corpus; ignoring.\n",
      "'whangamata' not in training corpus; ignoring.\n",
      "'scallop' not in training corpus; ignoring.\n",
      "'zumba' not in training corpus; ignoring.\n",
      "'davenport' not in training corpus; ignoring.\n",
      "'gigabyt' not in training corpus; ignoring.\n",
      "'courtesi' not in training corpus; ignoring.\n",
      "'fiddl' not in training corpus; ignoring.\n",
      "'nsc' not in training corpus; ignoring.\n",
      "'flu' not in training corpus; ignoring.\n",
      "'maryjan' not in training corpus; ignoring.\n",
      "'metenolon' not in training corpus; ignoring.\n",
      "'trace' not in training corpus; ignoring.\n",
      "'ghb' not in training corpus; ignoring.\n",
      "'rollin' not in training corpus; ignoring.\n",
      "'cocktail' not in training corpus; ignoring.\n",
      "'recept' not in training corpus; ignoring.\n",
      "'marriott' not in training corpus; ignoring.\n",
      "'marqui' not in training corpus; ignoring.\n",
      "'maggi' not in training corpus; ignoring.\n",
      "'ticketmast' not in training corpus; ignoring.\n",
      "'liz' not in training corpus; ignoring.\n",
      "'dna' not in training corpus; ignoring.\n",
      "'roadmap' not in training corpus; ignoring.\n",
      "'basement' not in training corpus; ignoring.\n",
      "'wil' not in training corpus; ignoring.\n",
      "'lyf' not in training corpus; ignoring.\n",
      "'invis' not in training corpus; ignoring.\n",
      "'coulda' not in training corpus; ignoring.\n",
      "'romania' not in training corpus; ignoring.\n",
      "'smfh' not in training corpus; ignoring.\n",
      "'goh' not in training corpus; ignoring.\n",
      "'mei' not in training corpus; ignoring.\n",
      "'depth' not in training corpus; ignoring.\n",
      "'chart' not in training corpus; ignoring.\n",
      "'coolamon' not in training corpus; ignoring.\n",
      "'trent' not in training corpus; ignoring.\n",
      "'greg' not in training corpus; ignoring.\n",
      "'rallo' not in training corpus; ignoring.\n",
      "'howden' not in training corpus; ignoring.\n",
      "'childhood' not in training corpus; ignoring.\n",
      "'bantam' not in training corpus; ignoring.\n",
      "'titss' not in training corpus; ignoring.\n",
      "'redpacket' not in training corpus; ignoring.\n",
      "'sputter' not in training corpus; ignoring.\n",
      "'leaderboard' not in training corpus; ignoring.\n",
      "'lick' not in training corpus; ignoring.\n",
      "'gipsi' not in training corpus; ignoring.\n",
      "'frieri' not in training corpus; ignoring.\n",
      "'induct' not in training corpus; ignoring.\n",
      "'section' not in training corpus; ignoring.\n",
      "'grimm' not in training corpus; ignoring.\n",
      "'howev' not in training corpus; ignoring.\n",
      "'wembley' not in training corpus; ignoring.\n",
      "'gunpowd' not in training corpus; ignoring.\n",
      "'split' not in training corpus; ignoring.\n",
      "'biden' not in training corpus; ignoring.\n",
      "'dsu' not in training corpus; ignoring.\n",
      "'mustach' not in training corpus; ignoring.\n",
      "'waaaaaay' not in training corpus; ignoring.\n",
      "'phuk' not in training corpus; ignoring.\n",
      "'cyclist' not in training corpus; ignoring.\n",
      "'bicyclefilmfestiv' not in training corpus; ignoring.\n",
      "'hammerstein' not in training corpus; ignoring.\n",
      "'bere' not in training corpus; ignoring.\n",
      "'ampro' not in training corpus; ignoring.\n",
      "'flashlight' not in training corpus; ignoring.\n",
      "'magnet' not in training corpus; ignoring.\n",
      "'isrt' not in training corpus; ignoring.\n",
      "'minotaur' not in training corpus; ignoring.\n",
      "'vindic' not in training corpus; ignoring.\n",
      "'rebel' not in training corpus; ignoring.\n",
      "'jarreau' not in training corpus; ignoring.\n",
      "'aircraft' not in training corpus; ignoring.\n",
      "'stray' not in training corpus; ignoring.\n",
      "'usaf' not in training corpus; ignoring.\n",
      "'interceptor' not in training corpus; ignoring.\n",
      "'warhead' not in training corpus; ignoring.\n",
      "'corker' not in training corpus; ignoring.\n",
      "'bon' not in training corpus; ignoring.\n",
      "'sting' not in training corpus; ignoring.\n",
      "'musician' not in training corpus; ignoring.\n",
      "'mayweath' not in training corpus; ignoring.\n",
      "'dve' not in training corpus; ignoring.\n",
      "'timezon' not in training corpus; ignoring.\n",
      "'halifa' not in training corpus; ignoring.\n",
      "'ayan' not in training corpus; ignoring.\n",
      "'yusuf' not in training corpus; ignoring.\n",
      "'hargeisa' not in training corpus; ignoring.\n",
      "'mlimani' not in training corpus; ignoring.\n",
      "'mabi' not in training corpus; ignoring.\n",
      "'everytim' not in training corpus; ignoring.\n",
      "'overlook' not in training corpus; ignoring.\n",
      "'summeri' not in training corpus; ignoring.\n",
      "'sheila' not in training corpus; ignoring.\n",
      "'muchoforex' not in training corpus; ignoring.\n",
      "'witch' not in training corpus; ignoring.\n",
      "'ara' not in training corpus; ignoring.\n",
      "'bagsakan' not in training corpus; ignoring.\n",
      "'parokya' not in training corpus; ignoring.\n",
      "'gloc' not in training corpus; ignoring.\n",
      "'baduy' not in training corpus; ignoring.\n",
      "'tagalog' not in training corpus; ignoring.\n",
      "'nga' not in training corpus; ignoring.\n",
      "'nindooooot' not in training corpus; ignoring.\n",
      "'jod' not in training corpus; ignoring.\n",
      "'kaayo' not in training corpus; ignoring.\n",
      "'dmd' not in training corpus; ignoring.\n",
      "'dick' not in training corpus; ignoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'distinguish' not in training corpus; ignoring.\n",
      "'conserv' not in training corpus; ignoring.\n",
      "'skillman' not in training corpus; ignoring.\n",
      "'foggiest' not in training corpus; ignoring.\n",
      "'roni' not in training corpus; ignoring.\n",
      "'witho' not in training corpus; ignoring.\n",
      "'tap' not in training corpus; ignoring.\n",
      "'maiden' not in training corpus; ignoring.\n",
      "'noah' not in training corpus; ignoring.\n",
      "'stewart' not in training corpus; ignoring.\n",
      "'margherita' not in training corpus; ignoring.\n",
      "'summon' not in training corpus; ignoring.\n",
      "'mol' not in training corpus; ignoring.\n",
      "'rglll' not in training corpus; ignoring.\n",
      "'chigozi' not in training corpus; ignoring.\n",
      "'agbim' not in training corpus; ignoring.\n",
      "'chibuzor' not in training corpus; ignoring.\n",
      "'okonkwo' not in training corpus; ignoring.\n",
      "'chickfila' not in training corpus; ignoring.\n",
      "'coupon' not in training corpus; ignoring.\n",
      "'tick' not in training corpus; ignoring.\n",
      "'wacki' not in training corpus; ignoring.\n",
      "'wacki' not in training corpus; ignoring.\n",
      "'pregam' not in training corpus; ignoring.\n",
      "'birdcag' not in training corpus; ignoring.\n",
      "'loftu' not in training corpus; ignoring.\n",
      "'trinamool' not in training corpus; ignoring.\n",
      "'sepang' not in training corpus; ignoring.\n",
      "'element' not in training corpus; ignoring.\n",
      "'triumph' not in training corpus; ignoring.\n",
      "'vick' not in training corpus; ignoring.\n",
      "'carr' not in training corpus; ignoring.\n",
      "'riski' not in training corpus; ignoring.\n",
      "'tactic' not in training corpus; ignoring.\n",
      "'backfir' not in training corpus; ignoring.\n",
      "'ff' not in training corpus; ignoring.\n",
      "'barbecu' not in training corpus; ignoring.\n",
      "'wiggl' not in training corpus; ignoring.\n",
      "'comp' not in training corpus; ignoring.\n",
      "'steadi' not in training corpus; ignoring.\n",
      "'skylin' not in training corpus; ignoring.\n",
      "'stranger' not in training corpus; ignoring.\n",
      "'unreleas' not in training corpus; ignoring.\n",
      "'likeeeeeeeee' not in training corpus; ignoring.\n",
      "'ident' not in training corpus; ignoring.\n",
      "'atlant' not in training corpus; ignoring.\n",
      "'uniform' not in training corpus; ignoring.\n",
      "'reunit' not in training corpus; ignoring.\n",
      "'bf' not in training corpus; ignoring.\n",
      "'vronski' not in training corpus; ignoring.\n",
      "'karenina' not in training corpus; ignoring.\n",
      "'banish' not in training corpus; ignoring.\n",
      "'uc' not in training corpus; ignoring.\n",
      "'egg' not in training corpus; ignoring.\n",
      "'florentin' not in training corpus; ignoring.\n",
      "'bundl' not in training corpus; ignoring.\n",
      "'usain' not in training corpus; ignoring.\n",
      "'shoe' not in training corpus; ignoring.\n"
     ]
    }
   ],
   "source": [
    "que=[]\n",
    "for i in test_x:\n",
    "    #evalSentence = input('Input a sentence to be evaluated, or Enter to quit: ')\n",
    "    evalSentence=i\n",
    "    if len(evalSentence) == 0:\n",
    "        break\n",
    "\n",
    "    # format your input for the neural net\n",
    "    testArr = convert_text_to_index_array(evalSentence)\n",
    "    inp = tokenizer.sequences_to_matrix([testArr], mode='binary')\n",
    "    # predict which bucket your input belongs in\n",
    "    pred = model.predict(inp)\n",
    "    k=np.amax(pred[0])\n",
    "\n",
    "    ind=list(pred[0]).index(k)\n",
    "\n",
    "    que.append(ind)\n",
    "    # and print it for the humons\n",
    "    #print(\"%s sentiment; %f%% confidence\" % (labels[np.argmax(pred)], pred[0][np.argmax(pred)] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6254901960784314\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "notp=0\n",
    "notn=0\n",
    "notq=0\n",
    "for i in range(len(que)):\n",
    "    if que[i]==test_y[i]:\n",
    "        count+=1\n",
    "    \n",
    "        \n",
    "print(count/len(que))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
